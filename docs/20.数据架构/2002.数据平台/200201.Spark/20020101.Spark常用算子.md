---
title: Spark常用算子
date: 2023-03-07 14:19:36
permalink: /pages/8e0c8a/
categories:
  - 大数据
  - Spark技术文档
tags:
  - Spark
author: 
  name: 不爱吃鱼的bobo
---

## 算子分类

### 按照类型

*   Transformation算子

*   Action算子

### 按照小方向分类

*   Value数据类型的Transformation算子，这种变换并不直接提交作业，针对处理的数据项是Value型的数据

*   Key-Value数据类型的Transformation算子，这种变换也不触发提交作业，针对处理的数据项是Key-Value型的数据对

*   Acion算子，会触发SparkContext提交Job作业

### Value数据类型的Transformation算子

#### 输入分区与输出分区一对一型

*   map算子

    *   将原来的RDD的每个数据项通过用户在map中自定义的函数f映射成一个新的元素，源码中的map算子相当于初始化一个RDD，新RDD叫做MappedRDD

        *   ![](https://api2.mubu.com/v3/document_image/6ea7bd6d-593a-4e7d-a2d0-35875c70425f-13037474.jpg)

*   flatMap算子

    *   将原来RDD的每个元素通过函数f映射转换为新的元素，并将生成的RDD的每个集合中的元素合并称为一个集合，内部创建FlatMappedRDD

        *   ![](https://api2.mubu.com/v3/document_image/3c3c51bb-94b5-41e5-8d8f-32eec9d9fb43-13037474.jpg)

*   mapPartitions算子

    *   mapPartitions算子获取到每个分区的迭代器，在函数中通过这个分区整体的迭代器对整个分区的元素进行操作，内部实现是生成MapPartitionsRDD

        *   ![](https://api2.mubu.com/v3/document_image/1fe2c1b1-2f0e-4222-ab67-e76f21a9d595-13037474.jpg)

*   glom算子

    *   glom函数将每个分区形成一个数组，内部实现是返回GlommedRDD

        *   ![](https://api2.mubu.com/v3/document_image/966bc57a-c517-46b9-8847-dc1720ca20b2-13037474.jpg)

#### 输入分区与输出分区多对一型

*   union算子

    *   union算子将两个元素数据类型一致的RDD，通过不去重（可以使用distinct去重）的拼接动作，保存所有元素，在Spark中可以使用“++”替代union动作

        *   ![](https://api2.mubu.com/v3/document_image/1f10da10-ae68-489f-b30f-24ff30b237cf-13037474.jpg)

*   cartesian算子

    *   将两个RDD内的与所有元素进行笛卡尔积操作，内部实现后返回CartesianRDD

        *   ![](https://api2.mubu.com/v3/document_image/b70f56ca-9772-4bc8-913e-f7a5eca304ca-13037474.jpg)

#### 输入分区与输出分区多对多型

*   groupBy算子

    *   将元素通过函数生成相应的Key，数据就转化为Key-Value格式，之后将Key相同的元素分为一组

        *   ![](https://api2.mubu.com/v3/document_image/f0fecec9-f4cb-4573-bd4e-2171b7c313bb-13037474.jpg)

#### 输出分区为输入分区子集型

*   filter算子

    *   filter函数将元素进行过滤，对每个元素应用f函数，并保留返回值为true的元素，其他元素将直接被过滤掉，内部实现相当于生成FilteredRDD

        *   ![](https://api2.mubu.com/v3/document_image/3aaaea67-a4c3-4eca-8436-530387bc1e9a-13037474.jpg)

*   distinct算子

    *   对RDD中的每个元素进行去重操作

        *   ![](https://api2.mubu.com/v3/document_image/719d49f9-c036-4311-abf1-16166bb67861-13037474.jpg)

*   subtract算子

    *   相当于进行集合的差操作，RDD1去重RDD1和RDD2交集中的所有元素

        *   ![](https://api2.mubu.com/v3/document_image/1fe7d63e-413f-403c-9f37-6423974d0e61-13037474.jpg)

*   sample算子

    *   sample对RDD这个集合中的元素进行采用，获取所有元素的子集，用户可以设定是否进行有放回的抽样、抽样百分比、随即种子，内部实现是生成SampledRDD

        *   ![](https://api2.mubu.com/v3/document_image/5dcb6469-f4d8-4c65-9aec-33ec6d01b32d-13037474.jpg)

*   takeSample算子

    *   抽样类算子，不实用比例抽样，而是设定采样个数，同事返回的结果不再是RDD，而是相当于对抽样后的数据进行collect()，返回结果为数组

        *   ![](https://api2.mubu.com/v3/document_image/ed9c87b9-19f4-457a-a770-1dc7415a86a8-13037474.jpg)

#### Cache型算子

*   cache算子

    *   将RDD元素从磁盘缓存到内存，相当于persist(MEMORY_ONLY)函数的功能

        *   ![](https://api2.mubu.com/v3/document_image/61aea16a-0243-4499-9921-107c886ff249-13037474.jpg)

*   persist算子

    *   将RDD进行缓存动作，根据StorageLevel进行确定缓存级别

        *   ![](https://api2.mubu.com/v3/document_image/f051c706-45f2-4f85-a93f-6625f21c1ead-13037474.jpg)

### Key-Value数据类型的Transformation算子

#### 输入分区和输出分区一对一型

*   mapValues算子

    *   针对（Key, Value）型数据中的Value进行map动作，对key不进行操作

        *   ![](https://api2.mubu.com/v3/document_image/143bb250-c4b1-41ef-91a5-24383da33d60-13037474.jpg)

#### 对单个RDD聚集

*   combineByKey算子

    *   可以支持用户自定义Combiner、Partitioner、mergeValue、序列化等函数进行combine

        *   ![](https://api2.mubu.com/v3/document_image/1400b89e-b4fc-475b-b50d-6abc4b0686ca-13037474.jpg)

*   reduceByKey算子

    *   combineByKey的一种简单情况，只是将两个值合为一个值

        *   ![](https://api2.mubu.com/v3/document_image/5f6b85b5-f383-4fa1-9c8d-f4b836befaf8-13037474.jpg)

*   partitionBy算子

    *   对RDD进行分区动作，如果原RDD分区器和现有的分区器一致时不重新分区，分则进行重分

        *   ![](https://api2.mubu.com/v3/document_image/e2c72634-c3c7-4b3e-85ad-0b19b004a70a-13037474.jpg)

#### 对两个RDD聚集

*   cogroup算子

    *   将两个RDD数据进行协同划分

        *   ![](https://api2.mubu.com/v3/document_image/ff285da0-abc7-4941-85a5-f2ed34a96c26-13037474.jpg)

#### 连接

*   join算子

    *   将两个需要联接的RDD进行cogroup操作，将相同的key的数据能够放到一个分区，在cogroup操作之后形成新RDD对每个Key下的元素进行笛卡尔积的操作，返回的结果再展平，对应key下的所有元组形成一个集合，最后返回RDD[(K, (V, W))]

        *   ![](https://api2.mubu.com/v3/document_image/e9283faa-dbeb-4764-8ffe-48614af896ae-13037474.jpg)

*   leftOutJoin和rightOutJoin算子

    *   在join的基础上对数据的一侧进行判断，如果为空就填充为空，如果不为空则将数据进行连接运算。

### Action算子

#### 无输出

*   foreach算子

    *   对RDD中的每个元素都应用函数f操作，不返回RDD和Array，返回Unit

        *   ![](https://api2.mubu.com/v3/document_image/9dd7d1ab-a56e-40ab-90b1-1251abf78465-13037474.jpg)

#### 输出File算子

*   saveAsTextFile算子

    *   内部调用saveAsHadoopFile进行实现，图片中左侧方框表示RDD分区，右侧表示HDFS的Block

        *   ![](https://api2.mubu.com/v3/document_image/2e7a9a36-4769-42b0-887e-c32ff46320e8-13037474.jpg)

*   saveAsObjectFile算子

    *   将分区中的每是个元素组成一个Array，然后将这个Array序列化，映射为(Null, BytesWritable(Y)) 的元素，写入HDFS为SequenceFile格式

        *   ![](https://api2.mubu.com/v3/document_image/f116cbda-0a3e-4d24-95e2-ba908ce3e930-13037474.jpg)

#### Scala集合和数据类型

*   collect算子

    *   collect相当于toArray，将分布式的RDD返回为一个单机的Scala Array数组，然后在这个数组上运用Scala函数式操作

        *   ![](https://api2.mubu.com/v3/document_image/7654f8a8-992c-47bb-9f9f-60be22e89ecf-13037474.jpg)

*   collectAsMap算子

    *   将k-v型的RDD数据返回为一个单机的HashMap，对于重复的Key，后面的元素会覆盖前面的元素

        *   ![](https://api2.mubu.com/v3/document_image/08da259e-682c-4fd4-af36-411cb0c92ff5-13037474.jpg)

*   reduceByKeyLocally算子

    *   是将RDD整体进行reduce操作，然后再收集所有的结果返回为一个HashMap

*   lookup算子

    *   Lookup函数对（Key，Value）型的RDD操作，返回指定Key对应的元素形成的Seq。 这个函数处理优化的部分在于，如果这个RDD包含分区器，则只会对应处理K所在的分区，然后返回由（K，V）形成的Seq。 如果RDD不包含分区器，则需要对全RDD元素进行暴力扫描处理，搜索指定K对应的元素

        *   ![](https://api2.mubu.com/v3/document_image/c74bd704-a9a2-42a5-a100-17c90216eaa0-13037474.jpg)

*   count算子

    *   返回整个RDD的元素个数，内部实现为 def count():Long = sc.runJob(this, Utils.getIteratiorSize_).sum

        *   ![](https://api2.mubu.com/v3/document_image/6a938dfe-b746-41ea-8fba-c292fe9603c3-13037474.jpg)

*   top算子

    *   top可以实现topK功能，top返回最大的k个元素，take返回最小的k个元素

*   reduce算子

    *   对于RDD中的元素进行reduceLeft函数操作，例如用户自定义f: (A, B) => (A._1 + "@" + B._1，A._2 + B._2)

        *   ![](https://api2.mubu.com/v3/document_image/233b1bbd-bba9-4fbd-9055-f43729a77703-13037474.jpg)

*   fold算子

    *   fold和reduce的原理相同，但是与reduce不同，相当于每个reduce时，迭代器取的第一个元素是zeroValue。用户自定函数　　fold(("V0@"，2)) ((A, B) => (A._1 + "@" + B._1, A._2 + B._2))

        *   ![](https://api2.mubu.com/v3/document_image/665e87f9-5183-4174-85fe-9b0d059b668a-13037474.jpg)

*   aggregate算子

    *   aggregate先对每个分区的所有元素进行aggregate操作，再对分区的结果进行fold操作。aggreagate与fold和reduce的不同之处在于，aggregate相当于采用归并的方式进行数据聚集，这种聚集是并行化的。 而在fold和reduce函数的运算过程中，每个分区中需要进行串行处理，每个分区串行计算完结果，结果再按之前的方式进行聚集，并返回最终聚集结果。图片第一次reduceLeft有错误

        *   ![](https://api2.mubu.com/v3/document_image/1ad99933-b552-4fd2-8772-45bd556583d5-13037474.jpg)