---
title: 华为数字化转型之道-平台底座篇
date: 2024-11-29 14:52:06
permalink: /pages/d59ed3/
categories:
  - 数据管理
  - 数字化转型
tags:
  - 
author: 
  name: 不爱吃鱼的bobo
---

## 1、统一数据底座

工欲善其事，必先利其器。

在从传统信息化向数字化转型的过程中，企业积累了海量数据，并且还在爆发式增长。数据很多，但真正能产生价值的数据却很少。数据普遍存在：

- 分散、不拉通
- 缺乏统一的定义和架构
- 找到想要的、能用的数据越来越难
- 大量资产价值难以体现

数据底座是数字化转型的关键能力之一，承接了打破数据孤岛、确保源头数据准确、促进数据共享、保障数据隐私与安全等目标。

## 2、华为数据治理历程

华为从**2007**年开始启动数据治理，历经两个阶段的持续变革，系统地建立了华为数据管理体系。第一阶段10年的持续投入为华为在**2016**年开始的数字化转型打下了坚实的基础。同时，在数字化转型蓝图的规划下，华为正式进入以建设统一的数据底座为核心的第二阶段，数据治理工作也迎来了新的挑战和发展。

### 2.1 第一阶段：2007-2016

这一阶段，华为设立数据管理专业组织，建立数据管理框架，发布数据管理政策，任命数据责任人（数据Owner），通过统一信息架构与标准、唯一可信的数据源、有效的数据质量度量改进机制，实现了以下目标。

1. **持续提升数据质量，减少纠错成本**：通过数据质量度量与持续改进，确保数据真实反映业务，降低运营风险。
2. **数据全流程贯通，提升业务运作效率**：通过业务数字化、标准化，借助IT技术，实现业务上下游信息快速传递、共享。

### 2.2 第二阶段：2017-至今

这一阶段，华为建设数据底座，汇聚企业全域数据并对数据进行连接，通过数据服务、数据地图、数据安全防护与隐私保护，实现了数据随需共享、敏捷自助、安全透明的目标。数据底座支撑着华为数字化转型，实现了如下数据价值。

1. **业务可视，能够快速、准确决策**：通过数据汇聚，实现业务状态透明可视，提供基于“事实”的决策依据
2. **人工智能，实现业务自动化**：通过业务规则数字化、算法化，嵌入业务流，逐步替代人工判断
3. **数据创新，成为差异化竞争优势**：基于数据的用户洞察，发现新的市场机会点

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/01_hw_data_gm_stage.png" width="80%" /></center>

### 2.3 治理愿景、目标和框架

基于公司多业务、全球化、分布式管理等业务战略规划和数字化转型诉求，华为明确了数据工作的愿景，即“**实现业务感知、互联、智能和ROADS体验（Real-Time、On-Demand、All-Online、DIY、Social），支撑华为数字化转型**”。华为数据工作的目标为“清洁、透明、智慧数据，使能卓越运营和有效增长”。为确保数据工作的愿景与目标达成，需要实现数据自动采集、对象/规则/过程数字化、数据清洁、安全共享等特性。

核心目的就是为了实现**“敏捷”和“低成本试错”**

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/02_hw_data_gm_target.png" width="80%" /></center>

作为非数字原生企业，我们认为**数字化转型的关键要素之一是在现实世界的基础上构建一个跨越孤立系统、承载业务的“数字孪生”的数字世界**。通过在数字世界汇聚、连接与分析数据，对业务进行描述、诊断和预测，最终指导业务改进。在实现策略上，数字世界一方面要充分利用现有IT系统的存量数据资产，另一方面要构建一条从现实世界直接感知、采集、汇聚数据到数字世界的通道，不断驱动**业务对象、过程与规则的数字化**。

#### 2.3.1 整体建设框架

基于数据建设工作的整体思路。整体建设框架基于统一的规则与平台，以业务数字化为前提、数据入湖为基础，通过数据主题联接并提供服务，建设数据底座，支撑业务数字化运营。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/04_hw_data_gm_build_struct.png" width="80%" /></center>

1. **数据源**：业务数字化是数据工作的前提，通过业务对象、规则与过程的数字化，不断提升数据质量，建立清洁、可靠的数据源。
2. **数据底座**：由数据湖和主题联接两部分组成。
   - **数据湖**：基于“统筹推动、以用促建”的建设策略，严格按6项标准，通过物理与虚拟两种入湖方式，汇聚华为内部和外部的海量数据，形成清洁、完整、一致的数据湖。
   - **数据主题联接**：通过5种数据联接方式，从规划和需求出发，建立数据主题联接，并通过服务支撑数据消费。
3. **数据消费**：对准数据消费场景，提供统一的数据分析平台，满足自助式数据消费需求。
4. **数据治理**：为保障各业务领域数据工作的有序开展，需建立统一的数据治理能力，如数据体系、数据分类、数据感知、数据质量、数据安全与隐私等。

### 3、支持数字化转型的数据底座

从数据建设工作的整体框架中可以看出，数据底座在数字化转型中起着关键作用。数据底座可以将公司内外部的数据汇聚在一起，对数据进行重新组织和连接，让数据有清晰的定义和统一的结构，并在尊重数据安全与隐私的前提下，让**数据更易获取，最终打破数据孤岛和垄断**。

### 3.1 数据底座的整体架构

通过数据底座，我们主要希望实现如下目标。

1. **统一管理结构化、非结构化数据**。将数据视为资产，能够追溯数据的产生者、业务源头以及数据的需求方和消费者等。
2. **打通数据供应通道，为数据消费提供丰富的数据原材料、半成品以及成品**，满足公司自助分析、数字化运营等不同场景的数据消费需求。
3. **确保公司数据完整、一致、共享。监控数据全链路下的各个环节的数据情况**，从底层数据存储的角度，诊断数据冗余、重复以及“僵尸”问题，降低数据维护和使用成本。
4. **保障数据安全可控**。安全是基本红线，基于数据安全管理策略，利用数据权限控制，通过数据服务封装等技术手段，实现对涉密数据和隐私数据的合法、合规消费。

华为数据底座由数据湖、数据主题联接两层组成，将公司内外部的数据汇聚到一起，并对数据进行重新的组织和连接，为业务可视化、分析、决策等提供数据

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/05_hw_data_leap_build_struct.png" width="80%" /></center>

数据湖是逻辑上各种原始数据的集合，除了**“原始”**这一特征外，还具有**海量和多样（包含结构化、非结构化数据）**的特征。数据湖保留数据的原格式，原则上不对数据进行清洗、加工，但对于数据资产多源、异构的场景则需要整合处理，并进行数据资产注册。
数据主题联接是对数据湖的数据按业务流/事件、对象/主体进行连接和规则计算等处理，形成**面向数据消费的主题数据**，具有多角度、多层次、多粒度等特征，支撑业务分析、决策与执行。基于不同的数据消费诉求，数据连接方式主要分为**多维模型(维度建模)、图模型、指标、标签、算法模型**5种。

### 3.2 数据底座的建设策略和原则

数据底座建设**不能一蹴而就（既要抬头看天，也要低头看路）**，**要从业务出发，因势利导，持续进行**。为了有效推动公司统一数据底座建设，华为公司变革指导委员会进行了两次讨论，明确了数据底座的建设策略。

- 第一，成立公司级数据资产管理变革项目，制订数据底座的建设规范和方法，构建数据底座建设所需的能力和平台，统筹推动数据底座建设。
- 第二，各领域依托其数字化转型相关变革项目，遵从统一的方法和规范，负责本领域数据资产的梳理和底座内容建设。
  具体来说，华为数据底座采取“统筹推动、以用促建、急用先行”的建设策略，根据公司数字化运营的需要，由公司数据管理部统一规划，各领域分别建设，以满足本领域和跨领域的数据需求。其中，数据Owner是各领域数据底座建设的第一责任人，各领域数据部门负责执行。

数据底座资产建设遵从下面4项原则。

1. 数据安全合规原则。数据底座的数据资产应遵循用户权限、数据密级、隐私级别等管理要求，以确保数据在存储、传输、消费等全过程中的安全。技术手段包括但不限于授权管理、权限控制、数据加密、数据脱敏。**原则上，敏感的个人数据不入数据底座**。
2. **需求和规划双轮驱动**原则。数据底座的数据资产基于业务规划和需求触发双驱动的原则进行建设，对核心数据资产优先建设。
3. 数据供应多场景原则。数据底座资产供应需根据业务需求提供离线/实时、物理/虚拟等不同的数据供应通道，满足不同的数据消费场景。
4. 信息架构遵从原则。数据底座的数据资产应遵从公司的信息架构，必须经IA-SAG（信息架构专家组）发布并完成注册。

具体来说，华为数据底座采取“**统筹推动、**<font color='red'>**以用促建**</font>**、急用先行**”的建设策略，根据公司数字化运营的需要，由公司数据管理部统一规划，各领域分别建设，以满足本领域和跨领域的数据需求。其中，**数据Owner是各领域数据底座建设的第一责任人**，各领域数据部门负责执行。

### 3.3 数据湖

数据湖是数据底座的基础部分，是逻辑上对各种原始数据的汇聚和集合，数据湖保留了数据的原格式，不对数据进行清洗和加工。华为数据湖面向各领域，**实现数据资产找得到、可理解、可信任，是数据主题联接和数据消费的基础**。

#### 3.3.1 华为数据湖的特点

华为数据湖是逻辑上对内外部、结构化、非结构化的原始数据的逻辑汇聚。数据入湖要**遵从6项入湖标准（数据源质量至关重要）**，以保证入湖数据的数据质量。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/06_hw_data_collect_rule.png" width="80%" /></center>

数据入湖的方式包括**物理入湖和虚拟入湖**。采用物理入湖时，原始数据将被物理存储在数据湖的物理表中；采用虚拟入湖时，原始数据不在数据湖中进行物理存储，而是通过建立对应虚拟表的集成方式实现入湖（通过多源数据或即席查询、Unity Catalog等进行处理，对业务数据库有一定行性能消耗）。两种方式相互协同，面向不同的消费场景共同满足数据连接和用户数据消费需求。

华为数据湖主要有以下几个特点。

1. **逻辑统一**。华为数据湖不是一个单一的物理存储，而是根据数据类型、业务区域等多个不同的物理存储构成，并通过统一的元数据语义层进行定义、拉通和管理。
2. **类型多样**。数据湖存放所有不同类型的数据，包括企业内部IT系统产生的结构化数据、业务交易和内部管理的非结构化的文本数据、公司内部园区各种传感器检测到的设备运行数据以及外部的媒体数据等。
3. **原始记录**。华为数据湖是对原始数据的汇聚，不对数据做任何的转换、清洗、加工等处理，保留数据最原始特征，为数据的加工和消费提供丰富的可能

#### 3.3.2 入湖的基本原则

数据入湖是数据消费的基础，需要严格满足入湖的6项标准，包括**明确数据Owner、发布数据标准、认证数据源、定义数据密级、数据质量评估、元数据注册**。通过这6项标准保证入湖的数据都有明确的业务责任人，且各项数据都可理解，同时都能在相应的信息安全保证下进行消费。

##### 3.3.2.1 明确数据Owner

数据Owner主要由数据产生所对应的流程Owner来担任，是所辖数据端到端管理的责任人，负责对入湖的数据定义数据标准和密级，承接数据消费中的数据质量问题，并制订数据管理工作路标，持续提升数据质量。

##### 3.3.2.2 发布数据标准

入湖数据要有相应的业务数据标准。业务数据标准描述公司层面需共同遵守的“属性层”数据含义和业务规则，是公司层面对某个数据的共同理解，这些理解一旦明确并发布，就需要作为标准在企业内被共同遵守。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/07_hw_data_collect_data_metadata_info.png" width="80%" /></center>

##### 3.3.2.3 认证数据源

**认证数据源，以确保数据从正确的数据源头入湖**。认证数据源需遵循公司数据源管理的要求，一般数据源是指业务上首次正式发布某项数据的IT系统，并经过数据管理专业组织认证。**认证过的数据源作为唯一数据源头被数据湖调用**。当承载数据源的IT系统出现合并、分拆、下线情况时，需及时对数据源进行失效处理，并启动新数据源认证。

##### 3.3.3.4 定义数据密级

定义数据密级是数据入湖的必要条件，为了确保数据湖中的数据能充分共享，同时又不发生信息安全问题，入湖的数据必须要定密。数据定密的责任主体是数据Owner，数据管家有责任审视入湖数据密级的完整性，并推动、协调数据定密工作。数据密级定义在属性层级，根据资产的重要程度，定义不同等级。不同密级的数据，有相应的数据消费要求。同时，为了促进公司数据的消费，数据湖中的数据有相应的降密机制，到降密期或满足降密条件的数据应及时降密，并刷新密级信息。

##### 3.3.3.5 数据质量评估

数据质量是数据消费结果的保证。数据入湖不需要通过清洗数据来提升数据质量，但需要对数据质量进行评估，让数据消费人员了解数据的质量情况，并了解消费该数据的质量风险。同时数据Owner和数据管家可以根据数据质量评估的情况，推动源头数据质量的提升，满足数据质量的消费要求。

##### 3.3.3.6 元数据注册

元数据注册是指将入湖数据的**业务元数据和技术元数据**进行关联，包括逻辑实体与物理表的对应关系，及业务属性和表字段的对应关系。连接业务元数据和技术元数据的关系，能够支撑数据消费人员通过业务语义快速地搜索到数据湖中的数据，降低数据湖中数据消费的门槛，让更多的业务分析人员能理解和消费数据。

#### 3.3.3 数据入湖的方式

**数据入湖遵循华为信息架构，以逻辑数据实体为粒度进行入湖**。逻辑数据实体在首次入湖时应该考虑信息的完整性，原则上一个逻辑数据实体的所有属性应该一次入湖，避免一个逻辑实体多次入湖，增加入湖工作量。

数据入湖的方式主要有**物理入湖和虚拟入湖**两种。根据数据消费的场景和需求，一个逻辑实体可以有不同的入湖方式。两种入湖方式相互协同，共同满足数据连接和用户数据消费需求。数据管家有责任根据消费场景的不同，提供相应的入湖数据。

物理入湖是指将原始数据复制到数据湖中，包括批量处理、数据复制同步、消息和流集成等方式。**虚拟入湖是指原始数据不在数据湖中进行物理存储，而是通过建立对应虚拟表的集成方式实现入湖，实时性强，一般面向小数据量应用，大批量的数据操作可能影响源系统**。

数据入湖的5种主要技术手段包括**批量集成(Bulk/Batch Data Movement)、数据复制同步(Data Replication/Data Synchronization)、消息集成(Message-Oriented Movement of Data)、流集成(Stream Data Integration)、数据虚拟化(Data Virtualization)**。

|   入湖方式   | 适用场景                                                     |
| :----------: | ------------------------------------------------------------ |
|   批量集成   | **对于需要进行复杂数据清理和转换且数据量较大的场景，批量集成是首选**。通常，调度作业每小时或每天执行，主要包含ETL、ELT及FTP等工具。批量集成不适合低数据延迟和高灵活性的场景 |
| 数据复制同步 | **数据复制同步适用于需要高可用性和对数据源影响小的场景**。使用基于日志的CDC捕获数据变更，实时获取数据。数据复制同步不适合处理各种复杂的数据结构以及需要清理和转换复杂数据的场景 |
|   消息集成   | 消息集成通常通过API捕获或提取数据，**适用于处理不同数据结构以及需要高可靠性和复杂转换的场景**。尤其是对于许多遗留系统、ERP和SaaS应用来说，消息集成是唯一的选择。消息集成不适合处理大量数据的场景，如部分场景交易数据 |
|    流集成    | **流集成主要关注流数据的采集和处理，满足数据实时集成**，每秒处理数万、数十万甚至数以百万计的事件流。流集成不适合用于需要复杂数据清理和转换的场景 |
|  数据虚拟化  | 对于需要低延迟、高灵活性和临时模式（不断变化下的模式）的数据消费场景，数据虚拟化是一个很好的选择。在数据虚拟化的基础上，通过共享数据访问层，分离数据源和数据湖，减少数据源变更带来的影响，同时支持数据实时消费。数据虚拟化不适合处理大量数据场景 |

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/08_hw_data_collect_way.png" width="80%" /></center>

## 4、数据建模

数据消费已经不再局限于传统的报表分析，还要支持用户的自助分析、实时分析，通过数据的关联，支持业务的关联影响分析以及对目标对象做特征识别，进行特定业务范围圈定、差异化管理与决策等。这些分析需求也不再是对单一数据的分析，而是往往需要对跨领域的数据进行连接后再进行综合分析，也就是说，需要将数据整理加工为业务人员可理解、可使用的“信息”。

### 4.1 五大建模连接方式

目前，数据湖汇聚了大量的原始数据，使得用户不再需要到各个源系统调用数据，而是统一从数据湖调用。由于**数据湖中的数据零散且数据结构都与源系统一致，严格遵从三范式，即使每个数据都有详细的定义和解释，用户也很难知道数据之间的关联关系**。例如，终端BG做设备收入预测需要的数据有产品、订单、计划等超过150个物理表信息，如果这些表没有进行联接，没有形成有用信息，是很难支撑用户进行分析的。
华为在数据湖的基础上通过建立数据连接层，基于不同的分析场景，通过5类连接方式将跨域的数据连接起来，将数据由“原材料”加工成“半成品”和“成品”，以满足不同场景的数据消费需求

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/09_hw_data_model_ways.png" width="80%" /></center>

#### 4.1.1 维度建模（多维模型）

多维模型是面向业务的多视角、多维度的分析，通过明确的业务关系，建立基于事实表、维度表及二者之间的连接关系，实现多维数据查询和分析。例如，从时间、区域、产品、客户等维度对订货数据进行多视角、不同粒度的查询和分析。

**多维模型是依据明确的业务关系，建立基于维度、事实表以及相互间连接关系的模型，可实现多角度、多层次的数据查询和分析**。设计出稳定、易扩展、高可用的数据模型来支持用户消费对数据主题联接至关重要。
多维模型设计有4个主要步骤，包括确定**业务场景、声明粒度、维度设计和事实表设计**。

##### 4.1.1.1 确定业务场景

分析业务需求，识别需求中所涉及的业务流及其对应的逻辑数据实体和关联关系。如PO履行全流程可视，首先需要识别监控的具体业务环节（如发货、开票等），再根据这些业务环节识别其对应的逻辑数据实体及关联。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_kimball_step01.png" width="80%" /></center>

##### 4.1.1.2 声明粒度

粒度表示数据单元的细节程度或综合程度，细节程度越高，粒度越细；细节程度越低，粒度越粗。声明粒度是维度和事实表设计的重要步骤，**意味着精确定义事实表的每一行表示什么**。针对监控PO履行这个场景，在做设计时首先要确认是监控PO的履行，还是具体到每个PO行的履行，不同的粒度会对应不同的事实表。

##### 4.1.1.3 确定维度

**维度是观察和分析业务数据的视角，支持对数据进行汇聚、钻取、切片分析**。维度由层次结构（关系）、层级、成员、属性组成。维度可以分为基础树和组合树，维度基础树提供统一定义的、完整的层级结构和成员；维度组合树根据业务使用场景进行定制。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_kimball_step03.png" width="80%" /></center>

维度设计需要满足<font color='red'>**单一性、单向性和正交性**</font>。

- **单一性**。有且仅有一个视角，在同一个维度中不能穿插其他经营分析的视角。例如，区域维不含客户视角，产品维不含客户视角等。
- **单向性**。“上大下小”，维度只能支撑自上而下的分解和自下而上的收敛，每个成员只能存在向上的收敛路径，不能具备向上和向下两个方向的收敛逻辑。
- **正交性**。成员两两不相交，同一成员不能同时拥有多个上级成员。以产品维为例，华为向客户提供的设备或服务都只能被准确地分配到唯一叶子（最底层）节点，并以此路径进行收敛。

##### 4.1.1.4 事实表设计

事实表存储业务过程事件的性能度量结果，由**粒度属性（主键）、维度属性、事实属性和其他描述属性**组成。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_kimball_step04.png" width="80%" /></center>

粒度属性是事实表的主键，通常由原始数据的主键或一组维度属性生成。

**维度属性是从维度中继承的属性**，可以只继承主键作为事实表的外键，也可以继承维度中全部或其他部分的属性（维度退化）。在上述例子中，事实表中除了有币种ID，还可以有币种编码和币种名称等属性。

- 事实属性是可以对该颗粒度的事实进行定量的属性，大多数的事实表包括一个或多个事实字段。
- **同一事实表中不能存在多种不同粒度的事实**，比如PO行明细事实表中不应该包含PO总金额，否则PO总金额累加时会出现错误。
- 尽可能包含所有与业务过程相关的事实，不包含与业务过程无关的事实。比如在设计“订单下单”这个业务过程的事实表时，不应该存在“支付金额”这个支付业务过程的事实。
- 对于不可相加的事实，需要分解为可加的事实。比如比率，需要分解为分子和分母。
- 事实的数值单位要保持一致。

其他属性主要包括创建人、创建时间、最后修改人、最后修改时间等审计字段。

#### 4.1.2 图模型

图模型用于数据间的关联影响分析，通过建立数据对象以及数据实例之间的关系，帮助业务快速定位关联影响。例如，查看某国家原产地的项目的数据具体关联到哪个客户以及合同、订单、产品的详细信息时，可以通过图模型快速分析关联影响，支撑业务决策。

图模型由节点和边组成。节点表示实体或概念，边则由属性或关系构成。实体指的是具有可区别性且独立存在的某种事物，如某一个人、某一个城市、某一种植物、某一种商品等，是图模型中的最基本的元素。概念是对特征进行组合而形成的知识单元，主要指集合、类别、对象类型、事物的种类，例如人物、地理等。属性主要指描述实体或概念的特征或特性，例如人员的国籍、生日等。我们以“哲学家”为例设计图模型。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_graph.png" width="80%" /></center>

**图模型构建的关键步骤如下**：

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_graph_step.png" width="80%" /></center>

#### 4.1.3 标签

标签是对特定业务范围的圈定。在业务场景的上下文背景中，运用抽象、归纳、推理等算法计算并生成目标对象特征的表示符号，是用户主观观察、认识和描述对象的一个角度。例如，对用户进行画像，识别不同的用户群，为产品设计和营销提供策略支持。

标签是根据业务场景的需求，通过**对目标对象（含静态、动态特性）运用抽象、归纳、推理等算法得到的高度精练的特征标识**，用于差异化管理与决策。标签由标签和标签值组成，打在目标对象上。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_label.png" width="80%" /></center>

标签是由互联网行业引入其他行业的，打标签的对象也由用户、产品等扩展到渠道、营销活动等。在互联网行业，标签有助于实现精准营销、定向推送、提供个性化用户体验等；在其他行业，标签更多助力于战略分级、智能搜索、提升运营、精准营销、优化服务、智慧经营等。
标签分为**事实标签、规则标签和模型标签**

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_label_catrgory.png" width="80%" /></center>

标签管理分为**标签体系建设和打标签**。

##### 4.1.3.1 标签体系建设

1. 选定目标对象，根据业务需求确定标签所打的业务对象，业务对象范围参考公司发布的信息架构中的业务对象。

2. 根据标签的复杂程度进行标签层级设计。

3. 进行详细的标签和标签值设计，包括标签定义、适用范围、标签的生成逻辑等：

   - 事实标签应与业务对象中的属性和属性值保持一致，不允许新增和修改；

   - 规则标签按照业务部门的规则进行相关设计；

   - 模型标签根据算法模型生成。

##### 4.1.3.2 标签计算（打标签）

1. 标签的数据存储结构。打标签是建立标签值与实例数据的关系，可以对业务对象、逻辑数据实体、物理表或记录打标签。为了方便从“用户”视角查找、关联、消费标签，可增加用户表，将标签归属到该“用户”下。这里的“用户”是泛指，可以是具体的人，也可以是组织、部门、项目等。

2. 打标签的实现方法。根据不同标签类型，打标签的方法列举如下。

   - 事实标签：根据标签值和属性允许值的关系，由系统自动打标签。

   - 规则标签：设计打标签逻辑，由系统自动打标签。

   - 模型标签：设计打标签算法模型，由系统自动打标签

#### 4.1.4 指标数据

指标是对业务结果、效率和质量的度量。依据明确的业务规则，通过数据计算得到衡量目标总体特征的统计数值，能客观反映企业某一业务活动中的业务状况。例如，促销员门店覆盖率指标可以衡量一线销售门店促销员的覆盖程度。

指标是衡量目标总体特征的统计数值，是能表征企业某一业务活动中业务状况的数值指示器。指标一般由指标名称和指标数值两部分组成，指标名称及其含义体现了指标质的规定性和量的规定性两个方面的特点，指标数值反映了指标在具体时间、地点、条件下的数量表现。

通过指标计算逻辑是否含有叠加公式，可以把指标分为原子指标和复合指标两种类型。

1. **原子指标**。指标数据通过添加口径/修饰词、维度卷积而成，口径/修饰词、维度均来源于指标数据中的属性。
2. **复合指标**。由一个或多个原子指标叠加计算而成，其中的维度、口径/修饰词均继承于原子指标，不能脱离原子指标维度和口径/修饰词的范围去产生新的维度和口径/修饰词

指标和数据的关系如下：

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_metrics.png" width="80%" /></center>

- **指标数据**：承载原子指标的数据表。例如门店明细表，其中度量为门店数量，通过“门店编码”卷积；属性包括门店等级、门店状态、门店形象等级、组织等级等。
- **维度**：从属性中选取组织、渠道、门店形象等级。
- **口径/修饰词**：“门店状态”等于“有效”，“有无促销员”等于1。
- **原子指标**：由指标数据通过添加口径/修饰词、维度卷积而成，包括“促销员覆盖门店数量”“有效门店数量”。
- **复合指标**：由2个或2个以上指标叠加计算而成，促销员门店覆盖率=促销员覆盖门店数量÷有效门店数量

如何按需求进行指标拆解，是将指标对应到数据资产并进行结构化管理，以支持指标服务化与自助需求的关键。指标的拆解过程主要包括**指标拆解需求澄清、指标拆解设计、指标数据与数据资产匹配**3个阶段。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/10_hw_data_model_metrics_split.png" width="80%" /></center>

- **解读指标定义，识别指标**：通过与定义指标的业务管理部门沟通（通常为指标解释部门的业务人员），从业务角度了解指标基本信息、所需统计维度、指标度量场景以及各场景下的计算逻辑和口径（包括剔除规则）、指标发布信息等。
- **基于指标叠加公式拆解指标**：根据指标计算逻辑识别原子指标，明确原子指标中需要的口径/修饰词、维度信息，以及原子指标与复合指标间的支撑关系。
- **基于指标拆解结果，识别指标数据**：识别原子指标的度量属性和支撑属性，并根据原子指标中的维度、口径/修饰词匹配已发布业务对象的属性，形成指标数据。
- **数据落地匹配**：补充指标、指标数据中的标准属性名称以及对应的落地物理表，支持用户自助实现指标计算，拉通指标设计和落地。

#### 4.1.5 算法模型

算法模型面向智能分析的场景，通过数学建模对现实世界进行抽象、模拟和仿真，提供支撑业务判断和决策的高级分析方法。例如，预测未来18个月的销售量，需要数据科学家根据数据湖中的历史订单、发货等数据通过决策树和基因算法进行数据建模，支持业务决策。

## 5、面向安全的数据服务

**数据底座建设的目标是更好地支撑数据消费**，但是如何能够让用户使用数据更便捷，并且确保整个数据消费的过程安全、合规？

为了实现效率与安全兼顾的目标，华为公司大力推进数据服务建设，一方面将数据资产作为一种服务，更好地满足业务人员对效率、便捷的要求；另一方面通过服务机制实现安全可控，确保所有的数据资产在安全合规的前提下进行共享。

**数据服务的价值**：

- **保障数出一门，提升数据的一致性**。通过服务获取数据的方式更类似于“阅后即焚”，大部分情况下数据并不会在使用方所在系统中保存，因此减少了数据“搬家”，而一旦数据的使用方并不拥有数据，就减少了向下游二次传递所造成的数据不一致问题。
- **数据使用者不用关注技术细节，满足不同类型的数据服务需求**。对于数据使用者而言，不用再关心“我要的数据在哪里”，例如用户不需要知道这些数据在哪个系统、哪个数据库、哪个物理表，只需要清楚自身的数据需求，就能找到对应的数据服务，进而获取数据。
- **提升数据敏捷响应能力**。数据服务一旦建设完成，并不需要按使用者重复构建集成通道，而是通过订阅该数据服务快速获取数据。
- **满足用户灵活多样的消费诉求**。数据服务的提供者并不需要关心用户怎么消费数据，避免了供应方持续开发却满足不了消费方灵活多变的数据使用诉求的问题。
- **兼顾数据安全与合规**。所有数据服务的使用都可管理，数据供应方能够准确、及时地了解谁使用了自己的数据，并且各种安全措施都可以在数据服务建设中落实，确保数据使用的合规，数据消费遵循目的限制原则。

数据服务的分类：

- 数据集服务：最主要的特征，是由服务提供方提供相对完整的数据集合，消费方访问数据集合，并自行决定接下来的处理逻辑。

  - 数据服务提供方被动地公开数据以供数据消费方检索。

  - 数据服务提供方并不定义数据处理逻辑，但数据和数据处理逻辑仍然由其控制。

  - 服务的生命周期即数据访问授权的有效期。

- 指标数据服务：自助取数分析、BI 报表

- 数据API服务

### 5.1 数据服务SLA

数据服务改变了传统的数据集成和消费的方式，数据都通过服务对外提供，用户不再直接集成数据，而是通过服务获取。因此，数据服务应该拉动数据供应链条的各个节点，以方便用户能准确地获取数据为重要目标。华为为确保整个数据供应链条的高效协同，制订了“三个1”标准作为拉通各个供应环节的整体目标，以确保每个环节能够形成合力并对准最终用户。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/11_hw_data_service_sla.png" width="80%" /></center>

**“三个1”**是数据服务供应的整体目标，起点是需求方提出数据需求，终点为需求方拿到数据并可立即进行消费，具体衡量标准如下。

- 1天：已发布数据服务场景，从需求提出到消费者通过服务获取数据，在1天内完成。
- 1周：已进数据底座但无数据服务场景，从需求提出、数据服务设计落地到消费者通过服务获取数据，在1周内完成。
- 1个月：已结构化但未进数据底座场景，从需求提出、汇聚入湖、数据主题联接、数据服务设计落地到消费者通过服务获取数据，在1个月内完成。

数据供应的“三个1”并不是单纯的度量指标，而是一整套瞄准最终数据消费体验的供应能力和相应管理机制建设，还包括组织职责的明确、流程规范的制订与落实、IT平台的建设和管理.

## 6、数据地图

在过去，数据供应者与消费者之间往往存在一种矛盾，当供应者做了大量的数据治理工作、提供了大量的数据后，数据消费者却仍然不满意，他们始终认为在使用数据之前，存在两个重大困难。

1. **找数据困难**
   企业数据分散存储在上千个数据库、上百万张物理表中，已纳入架构、经过质量和安全有效管理的数据资产也会超过万个，并且还在持续增长中。

   例如，用户需要从发货数据里对设备保修和维保进行区分，以便为哪类设备已过保、无法继续服务提供准确依据，但生成和关联的交易系统有几十个，用户不知道从哪里能拿到这类数据，也不清楚取得的数据是否正确。

2. **数据读不懂**
   企业往往存在数据库物理层和业务层脱离的现状：数据的最终消费者无法直接读懂物理层数据，无法确认识别的数据是否能满足需求，只能寻求IT人员帮助，经过大量转换和人工校验后，才能最终确认可消费的数据，而熟悉物理层结构的IT人员，并不是数据的最终消费者。

​	例如，当需要盘点研发内部要货情况时，就需要从供应链系统获取研发内部要货数据，但业务人员不了解该系统复杂的数据存储结构（涉及40多张表、1000多个字段），也不清楚每个字段名称下所包含的业务含义和规则。

企业在经营和运营过程中产生了大量数据，但只有让用户找得到、读得懂，能够准确地搜索、便捷地订阅这些数据，数据才能真正发挥价值，这就需要打造一张能够满足用户体验的数据地图。

数据地图(DMAP)是华为面向数据最终消费者对数据找得到、读得懂的需求而设计的，是基于元数据应用，以数据搜索为核心，通过可视化方式，综合反映有关数据的来源、数量、质量、分布、标准、流向、关联关系，让用户高效率地找到数据、读懂数据，支撑数据消费的一款产品。

数据地图作为数据治理成果的集散地，需要提供多种数据，承接多类用户、多样场景的数据消费需求，所以华为结合业务实际，构建了如图所示的数据地图框架。

<center><img src="/donot-eat-fish/img/data_management/100204.华为数字化转型平台篇/11_hw_data_map_user.png" width="80%" /></center>

数据地图为4类关键用户群体提供服务。

1. **业务分析师**。主要群体，业务分析师是企业最大的数据消费群体，具有良好的业务背景，有些业务分析师本身就是业务人员，了解业务需求实质，理解业务含义，与利益相关者有良好的沟通，通过对数据的识别，借助数据分析工具，生成可供阅读的图表或者仪表板，使用分析结果识别问题，支撑决策。这类用户对数据可信度、业务含义、数据定位有强烈诉求。
2. **数据科学家**。数据科学家是指能采用科学方法、运用数据挖掘工具对大量复杂的数字、符号、文字、网址、音频或视频等信息进行数字化重现与认识，并能寻找新的数据洞察的工程师或专家。这类用户对业务含义、数据关系有强烈诉求。
3. **数据管家**。公司数据管理体系的专业人员，负责协助数据Owner对信息架构进行管理，包括定义信息架构中的责任主体、密级/分类，为数据安全管理提供重要输入。通过信息架构设计，统一业务语言，明确管理责任，设定数据质量标准，拉通跨领域信息流，支撑运营和决策。这类用户对数据质量、信息架构、数据关系有强烈诉求。
4. **IT开发人员**。主要为企业数据仓库开发人员，通过对物理表定位、识别和ETL，创建满足业务分析师或者应用平台所需要的模型或维表。这类用户对数据定位、数据关系有强烈诉求。数据地图重点提供数据搜索、排序、推荐以及数据样例、数据资产、用户画像等关键能力。
