---
title: 初识数仓开发和维度建模
date: 2024-08-15 14:46:23
permalink: /pages/3buil3de/
author: 
  name: 褚文笛
tags: 
  - 技术系列
  - 数据仓库
  - 维度建模
categories: 
  - 数据管理
  - 数据治理
---

## 1 数据仓库

### 1.1 数仓的定义

A Data Warehouse is a **subject oriented**, **integrated**, **nonvolatile**, and **time variant** collection of data in support of management’s decisions.

——数据仓库创始人Bill Inmon

**面向主题的**：数据仓库中的数据是围绕特定的业务主题进行组织的，如客户、销售、供应链等

**综合的**：来自多个不同的数据源

**稳定的**：加载到数仓中的数据往往不会被修改删除，使得历史数据可以被保留和长期分析

**随时间变化的**：按照时间维度进行组织，每条记录通常都带有时间戳，记录里数据在特定时间点或时间段的状态

### 1.2 数据仓库 vs. 数据库

|  | 数据库 | 数据仓库 |
| --- | --- | --- |
| 设计目标 | 主要用于OLTP，常用于电子商务、银行、客户关系等场景，支持快速的数据插入、更新、删除操作 | 主要用于OLAP，用于存储和分析大量的历史数据，支持复杂的查询和数据分析，常用于BI、报表生成、数据分析等场景 |
| 数据结构 | 高度规范化，3NF，减少冗余，提高数据插入、更新、删除效率 | 通常用去规范化结构，如星型模式，以优化查询性能 |
| 数据处理 | 支持CRUD，主要用于事务处理；支持高并发读写操作，确保数据一致性和完整性 | 主要支持读取操作，数据插入和更新通常是批量处理（如ETL过程）；主要关注查询的并发性和性能优化，而不是高并发写入 |
| 数据更新时间 | 实时更新，数据通常都是当前的 | 定期更新（如每周、每天），通常包含历史数据，不一定最新 |
| 用户和访问方式 | 用户：通常是应用程序和直接与事务相关的用户；访问方式：高频率、低复杂度的查询和操作 | 用户：通常是数据分析师、商业智能用户和决策者；访问方式：低频率、高复杂度的查询和分析操作 |

### 1.3 数仓的架构

![数仓分层示意图](../.vuepress/public/img/14.dw_develop_data_model_build/data_warehouse_layer.png)

### 1.4 数仓模型质量评价

1. 完善度
    - DWD层完善度：ODS被跨层引用越少越好，数据中台模型设计规范中，不允许跨层引用，ODS层只能被DWD层引用
    - DWS、ADS、DM层完善度：考核汇总数据完善度，看汇总数据能直接满足多少查询需求，即DWS/ADS/DM层的查询占所有查询的比例。该值越高，说明上层数据建设越完善，对于使用数据的人来说，查询速度更快、查询成本减少
2. 复用度

    ![复用性示意图](../.vuepress/public/img/14.dw_develop_data_model_build/duplicate_use_sample.png)

    数据中台模型设计的核心是追求模型的复用和共享。一个较差的设计是自下而上一条线，一个理想的模型设计应该是交织的发散型结构。用模型引用系数作为指标：一个模型被读取，直接产出下游模型的平均数量。

3. 规范性
    
    模型设计层面，表需要分层信息和归属的主题域（例如交易域），如果没有归属主题域，就很难找到这张表，也无法复用。
    
    表的命名上，需要包括主题域、分层、全量还是增量、更新频率等信息。
    
    字段命名上，相同含义的字段在不同表中命名需要一致，反之则一定要有区分。
    

## 2 数据建模

### 2.1 数据建模概述

数据建模是为了规划和展示数据库中数据的结构及其相互关系，确保数据库能够有效支持业务需求。

数据建模是创建数据流图表的过程

- 创建新数据库结构或备用数据库结构时，设计人员会先创建一个数据流图表，设计数据流入和流出数据库的方式。
- 数据流图表用于定义数据格式、结构和数据库处理功能的特性，以便有效地满足数据流需求。构建和部署数据库后，数据模型将保留下来。
- 根据数据模型，我们可以了解创建数据库的原因以及数据流的设计。

另一方面，数据建模是对业务收集和生成的所有不同数据以及这些数据之间关系进行分析和定义的过程。建模过程生成的数据模型会提供一个框架，说明数据库中各种数据元素之间的关系，并为数据的使用提供指导。

**数据建模的目标**：有序、有结构地分类组织和存储，在性能、成本、效率、质量之间取得最佳平衡

### 2.2 数据建模类型

1. 关系型：较老、最常用。关系型模型是通过表（表格）来组织和存储数据的，每个表格包含行（记录）和列（字段）。表与表之间通过键（如主键和外键）进行关联。
    
    用途：关系型模型适用于传统数据库管理系统，是大多数企业应用的基础，广泛用于事务处理和结构化数据存储
    
2. 维度型：相对宽松，结构更灵活，适用于更贴合业务用途或情境的情境型数据结构。关键数据元素（如交易数量）称为事实，其附带称为维度的参考信息（如产品标识、单价、交易日期等）。事实表是维度模型的主表。该模型将特定活动的数据存储在一起，可以提高检索效率。
    
    用途：维度型模型广泛用于数据仓库和商业智能应用，旨在优化数据查询和分析效率。
    
3. 实体关系型（E-R）：E-R模型通过实体（如客户、订单）及其关系来表示数据结构，每个实体都有相应的属性（如客户名、订单号）。E-R模型以图形形式呈现业务数据结构，活动、功能或实体以各种形状的框表示，而实体之间的关联通过关系线表示。
    
    用途：E-R模型通常用于数据库设计的初期阶段，用来直观地展示数据之间的关系，帮助设计人员理解系统的结构和需求。
    

### 2.3 数据抽象概念级别

数据模型类型很多，可能的布局类型也很多，在数据处理方面，有三种公认的建模方式，分别代表模型开发时的思维抽象级别

1. 概念数据模型（第一级）：全局模型，表示整体结构和内容，不包含数据计划的详细信息。数据建模通常从这一级开始，旨在确定各种数据集和整个企业中的数据流。概念模型是开发逻辑模型和物理模型的总体蓝图，也是数据架构文档化的重要内容。
2. 逻辑数据模型（第二级）：最接近数据模型的一般定义，旨在描述数据流和数据库内容。逻辑模型向概念模型中添加了详细信息，但不包括数据库本身的规范。
3. 物理数据模型（第三级）：物理数据模型具体描述如何实现逻辑模型，必须包含充足的详细信息，使技术人员能够在软硬件中创建实际的数据结构，支持将使用该结构的应用。

## 3 维度建模

### 3.1 维度建模概述

维度建模是数据仓库建设中的一种数据建模方法，目标是使数据存储结构便于查询和分析。维度建模通常按照事实表和维度表来组织数据，简化复杂的数据关系。维度建模将客观世界划分为度量和上下文。

### 3.2 维度建模核心概念

1. 用于度量的事实
    
    事实可以看作是某个业务过程中的具体度量信息，通常是数值型的数据，用于量化某个业务事件。例如，销售额、订单数量、点击次数等。这些度量数据记录了业务活动的结果，是数据分析的核心内容。
    
2. 用于描述环境的维度表
    
    维度是提供这些事实数据的上下文信息，它们描述了事实发生的环境或背景。维度表中的数据通常是文本或分类信息，如时间、地点、产品、顾客等。维度帮助解释事实数据，并提供多角度分析的可能性。
    

### 3.3 维度建模架构类型

1. 星型模型

![星型模型示意图](../.vuepress/public/img/14.dw_develop_data_model_build/star_model.png)

一个事实表和多个非正规化的维度表组成，维度之间没有关联，每个维度表直接关联到事实表上。星型架构是一种非正规化的架构，其中存在一定冗余

2. 雪花模型

![雪花模型示意图](../.vuepress/public/img/14.dw_develop_data_model_build/snow_model.png)

雪花模型相当于将星型模型下的大维表拆分成了满足规范化设计（3NF）的小维表。然而实际上这种模式在实际应用中很少见，因为开发难度会增大，且数据冗余问题在数仓里并不严重。

### 3.4 维度建模步骤

1. 选择业务过程
    
    维度建模是紧贴业务的，必须以业务为根基，要根据运营提供的需求以及日后的易扩展性等进行业务的选择。
    
    比如商城，整个商城流程分为商家端、用户端、平台端，运营需求是总订单量、订单人数，及用户的购买情况等，我们选择业务过程就选择用户端的数据，商家及平台端暂不考虑。业务选择非常重要，因为后面所有的步骤都是基于此业务数据展开的。
    
2. 声明粒度
    
    维度建模要求在同一事实表中，必须具有相同的粒度。从给定的业务过程获取数据时，最好从原子粒度（最细粒度）开始设计。对于有明确需求的数据，建立针对需求的上卷汇总粒度。
    
    对于用户来说，一个用户有一个身份证号，一个户籍地址，多个手机号，多张银行卡，那么与用户粒度相同的粒度属性有身份证粒度，户籍地址粒度，比用户粒度更细的粒度有手机号粒度，银行卡粒度，存在一对一的关系就是相同粒度。
    
3. 确认维度
    
    维度表是作为业务分析的入口和描述性标识，所以也被称为数据仓库的“灵魂”。如果某列是对具体值的描述，是一个文本或常量，某一约束和行标识的参与者，此时该属性往往是维度属性。要确保维度表中不能出现重复数据，应使维度主键唯一。
    
4. 确认事实
    
    事实表是用来度量的，基本上都以数量值表示，事实表中的每行对应一个度量。最实用的事实就是数值类型和可加类事实，所以可以通过分析该列是否是一种包含多个值并作为计算的参与者的度量，这种情况下该列往往是事实。
    
5. *冗余维度
    
    考虑到提高下游用户使用效率、降低数据获取的复杂性、减少关联表的数量，通常在事实表中会冗余方便下游用户使用的常用维度
    

![维度建模实例图](../.vuepress/public/img/14.dw_develop_data_model_build/kimball_model_sample.png)

### 3.5 事实表分类

1. 事务事实表
    
    表中的一行对应空间或时间上某点的度量事件。事务事实表都包含一个与维度表关联的外键。并且度量值必须和事务粒度保持一致。
    
    什么是度量，就是指标，比如说销售金额，销售数量等这些可加的或者半可加就是度量值。
    
2. 周期快照事实表
    
    事务事实表可以很好跟踪一个事件，对其进行度量。但当需要一些状态度量时，比如账户余额、商品库存等，需要聚集与之相关的事务才能进行识别计算。
    
    顾名思义，周期事实表就是每行都带有时间值字段，代表周期，通常时间值都是标准周期，如某一天，某周，某月等。粒度是周期，而不是个体的事务，也就是说一个周期快照事实表中数据可以是多个事实，但是它们都属于某个周期内。
    
3. 累计快照事实表
    
    针对淘宝交易，设计了下单、支付、确认收货事务事实表，用于统计订单数、GMV等。但对于某些其他需求，如统计买家下单到支付的时长、支付到发货的时长等类似研究事件之间时间间隔的需求，采用累积快照事实表可以很好解决
    
    周期快照事实表是单个周期内数据，而累计快照事实表是由多个周期数据组成，每行汇总了过程开始到结束之间的度量。每行数据相当于管道或工作流，有事件的起点，过程，终点，并且每个关键步骤都包含日期字段。
    
4. 无事实的事实表
    
    我们以上讨论的事实表度量都是数字化的，当然实际应用中绝大多数都是数字化的度量，但是也可能会有少量的没有数字化的值但是还很有价值的字段，无事实的事实表就是为这种数据准备的，利用这种事实表可以分析发生了什么。
    
    淘宝卖家好中差评的度量更关注评价本身，没有数字化的度量，因此为无事实的事实表
    
5. 聚集事实表
    
    聚集，就是对原子粒度的数据进行简单的聚合操作，目的就是为了提高查询性能。
    
    如我们需求是查询全国所有门店的总销售额，我们原子粒度的事实表中每行是每个分店每个商品的销售额，聚集事实表就可以先聚合每个分店的总销售额，这样汇总所有门店的销售额时计算的数据量就会小很多。
    
6. 合并事实表
    
    这种事实表遵循一个原则，就是相同粒度，数据可以来自多个过程，但是只要它们属于相同粒度，就可以合并为一个事实表，这类事实表特别适合经常需要共同分析的多过程度量。
    

### 3.6 维度表相关概念

1. 维度表结构：谨记一条原则——包含单一主键。
2. 钻取（改变维的层次，变换分析的粒度）
    - 上卷（roll-up）：沿着维的层次向上聚集汇总数据。e.g. 对产品销售数据，沿着时间维上卷，可以求出所有产品在所有地区每月（或季度、年）的销售额。
    - 下钻（drill-down）：上卷的逆操作，沿着维的层次向下，查看更详细的数据。
3. 维度退化：有时维度除了主键没有其他内容，虽然也是合法维度键，但是一般会退回到事实表中，减少关联次数，提高查询性能。

## 4 公司内部数仓架构和设计

### 4.1 总体架构设计

**架构模式：**

公司内数仓采用Kappa架构代替Lambda架构

**计算引擎：**

要求：批流一体化，能同时进行事实和离线的操作；提供统一的sql interface， 方便开发人员和分析人员

采用Spark

**底层（事实数据）存储引擎：**

要求：数据in-flight，数据中途不落地，处理完后直接给到下游，最小化延迟；可靠性存储，有一定的持久化能力，高可用，支持数据重放

采用Iceberg+Hive

**中间（维度数据）存储引擎：**

要求：支持较大规模的查询（主要是和事实表进行join查询）；能够快速进行数据的实时更新

采用Iceberg+Hive

**集市层（明细/汇总数据）存储/查询引擎：**

要求：即席查询响应结果，支持业务历史数据、BI支持

采用Spark+Presto：使用Hive MetaStore进行数据管理，上层架设Presto作为查询引擎，用于快速进行OLAP，同时Presto可以对接各种BI分析工具，如MetaBase、Zeppelin、SuperSet。

**模型设计：**

维度建模选取业务过程，按照数据进行主题和域的划分，构建宽表、事实表、维度表。对用户经常访问的数据口径和维度，将其冗余存储在数据集市和事实表，提高使用效率，降低取数复杂性。主要模型类型：星型模型

### 4.2 数据分层

ODS、DWD、DWM、DWS、DIM、ADS、APP、TMP

![公司数仓架构示意图](../.vuepress/public/img/14.dw_develop_data_model_build/dw_struct_sample.png)

1. DIM维度层
    
    “数仓的能力直接与维度属性的质量和深度成正比”
    
    设计原则：
    
    - 尽可能生成丰富的维度属性。e.g. 电商公司商品维度可能有近百个维度属性，为下游的数据统计、分析、探查提供良好的基础
    - 尽可能多给出包含富有实际意义的文字性描述。e.g. 编码、文字并存，商品维度中商品ID用于不同表之间关联，商品名称、类目名称等用于报表标签
    - 区分数值型属性和事实。数值型字段是事实还是维度属性可根据字段的常用用途进行区分。e.g. 用于查询约束条件或分组统计，则是作为维度属性；用于参与度量的计算，则是作为事实
    - 尽量沉淀出通用的维度属性
    - 通过多表关联得到维度属性
    - 通过对单表的不同字段混合处理得到维度属性
    - 通过对单表的某个字段进行解析得到维度属性
    - 在维度类型中有一种重要的维度称为退化维度，是指直接将一些简单的维度放在事实表中。退化维度一般在分析中可以用于做分组，尤其是在星型模型中
    
    设计方法：
    
    - 选择维度或新建维度：作为维度建模的核心，在企业及数据仓库中必须保证维度的唯一性
    - 确定主维表：一般是ODS表，直接与业务系统同步
    - 确定相关维表：根据对业务的梳理，确定哪些表和主维表存在关联
    - 确定维度属性：分别从主维表、相关维表中选择维度属性或生成新的维度属性

1. ODS原始数据层
    
    将数据几乎无处理地存放在数据仓库系统中，结构上与源系统基本保持一致，是数据仓库的数据准备区
    
    数据同步及处理规范：
    
    - 数据同步规范：一个系统的源表只允许同步一次到数据仓库
    - 同步方式分为增量或全量同步两种
    - 数据加载与处理，数据集成同步全量数据时会直接进入全量表的当日分区
    - 全量初始化：对于每个同步表，全量初始化的数据都会独立存储在数据仓库的全量基线表中，表名的默认格式为源表名_base
    - 增量数据同步，增量数据会实时同步到数据仓库，并存储在增量日志表中，表名默认格式为源表名_log。每个同步表对应一个增量日志表，在同步增量数据时，将多条记录合并到一个文件并写入Iceberg
    - 全量数据合并，根据全量基线表和增量日志表得到某个时刻表的全量数据，并通过SQL合并全量数据至全量表。配置一个全量数据Merge节点，当全量数据完成Merge后，自动调度后续的计算分析节点
    - 所有ODS层的表都以统计日期分区表方式存储
    - 如果源系统的字段发生了变化（如新增、删除），ODS层对新增字段需要做相应的新增处理，对删除字段不做表结构变化，对修改字段拆分成删除、新增两个动作处理。

1. DWD明细层
    
    DWD层中主要存储事实表明细数据，事实表作为数据仓库维度建模的核心，紧紧围绕着业务过程进行设计。本数据库中事实表主要以事务性事实表和周期性事实表存储。
    
    设计原则：
    
    - 尽可能包含所有与业务过程相关的事实，即使存在冗余
    - 只选择与业务过程相关的事实。e.g. 订单交易业务流程中，在设计下单这个业务过程的事实表时，不能包含支付金额这个表示支付业务过程的事实
    - 在选择维度和事实之前，必须先声明粒度（数据行的最小单位）
    - 在同一事实表中，不能包含多种不同粒度的事实，表中所有事实的粒度需要与表声明的粒度一致。
    - 事实的单位要保持一致。在同一个事实表中，事实的单位应该保持一致。e.g. 原订单金额、订单优惠金额、订单运费金额三个事实，应该采用一致的计量单位，如同一为元。
    
    设计方法：
    
    - 为了便于独立研究，尽量对每个业务过程建立一个事实表
    - 声明粒度。通常粒度可以通过两种方式表述：一种是维度属性组合所表示的细节程度；一种是所表示的具体业务含义（例如商品）
    - 确定维度，选择可以准确描述业务过程所处环境的维度信息。e.g. 订单的买家、卖家、商品分类、时间等
    - 关联维度，事实表中通常只保留维度的外键。但是针对特殊场景、高频率情形，可以考虑将维度表关联到事实表中，提高对事实表过滤查询和聚合统计的效率

1. DWS聚集层
    
    本数仓在DWS层是主题域的基础下，以分析的主题对象为建模驱动，基于上层集市和指标需求构建单主题内多行为的汇总统计。
    
    聚集是指针对原始明细粒度的数据进行汇总。DWS汇总数据层是面向分析对象的主题聚集建模。e.g. 分析目标为：最近一天某个类目商品在各省的销售总额、该类目销售额Top10的商品名称、各省用户购买力分布等。因此我们可以以最终交易成功的商品、类目、买家等角度对最近一天的数据进行汇总。
    
    数据聚集的注意事项：
    
    - 聚集是不跨越事实的，只是针对原始星型模型进行的汇总。为获取和查询与原始模型一致的结果，聚集的维度和度量必须与原始模型保持一致。
    - 聚集会带来查询性能的提升，但是也会增加ETL维护的难度。当子类目对应的一级类目发生变更时，先前存在的、已经被汇总到聚集表中的数据根据需要确认是否重新调整。
    - 聚集设计时需要考虑结果表是否可以提供上卷、下钻的需求必要
    - 遵循数据公用性原则

1. ADS集市层
    
    数据集市或宽表。本数仓的ADS层可做跨主题域的宽表，通常按照业务域划分，由DWS和DWD层数据计算生成，如流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询、OLAP分析、数据分析等。可以在该层存放一些个性化的、不公用性的、复杂的指标。
    

**数据加工流程**

数据按照ODS-DWD-DWS-ADS-APP的层次，逐级汇总、提炼。在高层可以提供的数据，不再穿刺到下一场查询访问

- 业务系统原始数据、埋点数据通过数据抽取工具以批量、实时的方式进入ODS层
- 按照分层分域的维度模型加工数据保存到DWD和DWS层
- 各类数据应用从ADS、DWS提取所需要的数据，必要时访问DWD原始明细数据
- APP层汇总类结果禁止直接从DWD层获取

### 4.3 模型选择

| 比较点 | 维度建模 | 宽表 |
| --- | --- | --- |
| 扩展性 | 维度表变更，事实表可能不影响 | 维度变更可能导致很多宽表都要调整 |
| 耦合度 | 事实表和维度表解藕，某些粒度上不会因为维度表失败而影响聚合表的产出 | 一个非重要任务失败会导致整个宽表无法产出 |
| 组织方式 | 任务及工作流易组织 | 因高耦合导致任务之间盘根错节，不利于组织任务和工作流 |
| 数据一致性 | 企业级数据仓库总线架构的基石 | 底层如果没有维度建模支撑，容易陷入混乱 |
| 易用性 | 维表需要多几个维表关联 | 查询高效，维护难 |

所以在数据公共层（DWS、DWD）采用标准的维度建模方法-星型模型，而对于数据集市层（ADS）中优先考虑宽表进行跨主题域融合

### 4.4 主题域

| 域 | 主题 | 主要包含数据 |
| --- | --- | --- |
| 用户 | 设备主题 | 设备整机相关的标签数据 |
|  | 用户（个人）主题 | 用户（个人）相关标签数据（uid） |
|  | 电话 | 手机号为唯一标识 |
| 日志 | 设备 | 活跃、分布、激活、留存、时长 |
|  | 系统 |  |
|  | 内容 |  |
|  | 应用 |  |
| 交易 | 订单 | 实物订单、虚拟消费订单 、退换货 |
| 供应链 | 采购 | 采购相关数据 |
|  | 仓储 | 入库、出库 |
|  | 计划 | 计划相关数据 |
|  | 备货 | 备货相关数据 |
| 生产 | 生产 | 过站数、良数、不良数 |
| 人资 | 参与人 | 人力等 |
| 财务 | 财务 | 财务口径的销售统计 |
| 客服/客户服务 | 售后 | 设备维修 |
|  | 客服 | 咨询 |
| 营销 | 广告 | 广告相关数据 |
|  | 用户增长 | 用户增长相关数据 |
| 内容 | 应用数据 | , |
|  | 媒资数据 | 媒体资源数据：爱优腾芒、体育、知识付费等 |

### 4.5 一致性维度

一致性包括定义一致性、数据一致性、使用一致性、管理和维护一致性

以下为本数仓中的一致性维度，贯穿各个业务过程

| 维度 | 具体细分维度 | 说明 |
| --- | --- | --- |
| 日期 | 订单时间、支付时间、取消时间、行为时间 | 各种业务发生的日期 |
| 平台 |  |  |
| 用户 | sn,uid | 以用户ID为主键，用户相关属性 |
| 地区 | 国际分区、国家、省、市等行政划分 | 用户所属渠道，针对广告营销 |
| 产品 |  媒资、应用 |  |
| 渠道 | 销售渠道、获客渠道和创意 |  |
| 系统及版本 |  |  |
| 会员 | 不同会员身份 |  |
| 类型 | 费用类型、生产类型、货币类型 |  |

### 4.6 相关的原则和规范

**数据模型基本原则：**

1. 高内聚和低耦合：业务相近，高概率同时访问的数据放在一起，低概率同时访问的分开存储
2. 核心模型和扩展模型分离：核心模型包括最常用的核心业务，扩展模型包括一些个性化或少量应用的业务，保证核心模型的架构简洁性和可维护性
3. 公共处理逻辑下沉和单一：越是底层公用的处理逻辑越应该在数据调度依赖的底层进行封装和实现
4. 成本与性能平衡：适当的冗余可以换取查询和刷新性能，但不易过度冗余
5. 数据可回滚：处理逻辑不变，在不同时间多次运行，数据的结果不变
6. 一致性：具有相同含义的字段在不同表中命名必须相同，必须使用规范定义的名称
7. 命名清晰可理解：表命名需要清晰、一致，表名易于使用者理解和查询

**字段命名规范：**

1. 同名同义性是对字段命名的首要要求。如果两个字段名字一样，那么它们的含义应该是一样的；反之，如果两个字段名字不一样，那么它们的含义就一定是要有区别的。
2. 字段名称清晰是另外一个要求。良好的字段命名应当是自解释的，如果看完字段的注释还无法理解甚至曲解字段的含义，那个可以说这个字段的命名和注释是不合格的。
3. 字段格式统一，且不应丢失最小粒度。
4. ODS层字段默认使用源系统的字段名。
5. 请不要使用数字开头，或使用"a"、"b"、"c"这样子无明确意义的字段名。

**开发代码规范：**

代码格式统一、备注和注释清晰（关键步骤必须注释）、避免大范围和格式杂乱的脚本，合理利用临时表。 

1. 字段列对齐，不允许在一行中同时出现5个以上字段；
2. 关键字列对齐，在select中，","位于字段前；
3. 禁止使用tab，全部使用4个空格代替；
4. sql脚本结尾一定要有";"，且命名统一为".sql"

## 5 其他重要概念

### 5.1 数据湖

数据湖是一种大规模的数据存储架构，能够存储来自各种来源的结构化、半结构化和非结构化数据。数据湖的设计理念是提供一个中央存储库，允许数据科学家、分析师和其他用户在需要时访问和处理数据。与传统的数据仓库不同，数据湖通常以原始或接近原始的格式存储数据，不进行预处理。

**数据湖的关键特性**

1. 多样化的数据类型：
    数据湖能够存储各种类型的数据，包括结构化数据（如数据库表格）、半结构化数据（如JSON、XML）、非结构化数据（如文本、图像、视频）等。
2. 原始数据存储：
    数据湖通常保存数据的原始格式。这意味着数据在加载到数据湖时不需要进行模式定义或预处理，方便将来进行不同类型的分析。
3. 大规模存储和处理能力：
    数据湖通常基于云计算平台或分布式存储系统，能够存储和处理大规模数据。
4. 数据的灵活使用：
    数据湖允许不同类型的用户访问和处理数据，包括数据工程师、数据科学家、业务分析师等。用户可以根据需要对数据进行探索、转换和分析。
5. 低成本：
    相比传统数据仓库，数据湖的存储成本通常更低，因为它使用的是廉价的存储解决方案，且不需要进行复杂的数据模式设计和优化。

### 5.2 Iceberg

Apache Iceberg是一个用于大数据表格格式的开源项目，它为数据湖提供了一种表格管理层。数据湖通常用于存储各种类型的原始数据，但在管理这些数据时会遇到一些问题，如数据一致性、元数据管理、性能优化等。Iceberg作为一种表格格式和管理层，可以帮助解决这些问题，使得数据湖中的数据更易于使用和维护。

![Iceberg示意图](../.vuepress/public/img/14.dw_develop_data_model_build/iceberg_sample.png)

iceberg是计算与存储之间的中间层，它不绑定计算引擎也不依赖具体的存储系统。主要用于向下管理在存储系统上的文件，向上为计算层提供一些接口。

**Iceberg文件组织结构：**

![Iceberg结构图](../.vuepress/public/img/14.dw_develop_data_model_build/iceberg_sample.png)

1. xxx.meta.json文件：最高level文件，是表的元数据存储的位置，其中包含表的字段、分区、snapshot信息等。该类文件有多个，每一个是某一时刻表的元数据信息，当表更新（插入、删除、重写元数据）后，会再生成一个metadata.json
2. snap-xxx.avro文件：包含表的snapshot信息，每个snapshot对应一个该类型文件，内容是一个manifestList
3. xxx.avro文件：manifest文件，内容是一个数据文件的列表以及每个数据文件的统计信息

*snapshot：数据快照，是一种在特定时间点上捕获和保存数据库状态的技术。它是一种只读的拷贝，保存了数据库在创建快照时的所有数据和元数据的状态。数据库快照允许用户查看和恢复到某一时刻的数据状态，而不会影响到当前数据库的正常操作。

**Iceberg功能和优势**

1. 不绑定计算存储引擎：支持多种计算引擎（hive、spark、trino…）；支持多种存储系统（oss、hdfs、s3）
2. 基于快照的读写分离
3. 表、字段、分区变更：支持表的属性变更，支持添加/删除字段，支持添加/删除分区等，且不需要重刷数据
4. 流批统一的存储：同时支持批处理数据和流式数据存入iceberg表
5. 基于快照的增量读
6. time travel：支持时间旅行查询，可回滚到某个快照或时间点

### 5.3 OLAP与OLTP

数据处理一般分为两大类：联机分析处理OLAP（OnLine Analytical Processing）和联机事务处理（OnLine Transaction Processing）

**OLAP**是使用多维结构为分析提供对数据的快速访问的技术，OLAP的源数据通常存储在关系数据库的数据仓库中。OLAP是数仓的主要应用，支持复杂的分析操作，侧重决策支持。

**OLTP**也称为面向交易的处理系统，其基本特征是顾客的原始数据可以立即传送到计算中心进行处理，并在很短的时间内给出处理结果。OLTP是传统关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易、ERP、CRM、POS。

### 5.4 数据库范式

注：此处注意是数据库的范式，数据仓库通常是去规范化的结构

**第一范式（1NF）**：无重复的列，每一列都是不可分割的基本数据项。不满足1NF的数据库就不是关系数据库

**第二范式（2NF）**：属性完全依赖于主键

e.g. 选课关系表SelectCourse（学号，姓名，年龄，课程名称，成绩，学分），关键字为组合关键字（学号，课程名称）\
决定关系为：（学号，课程名称）—>（姓名，年龄，成绩，学分）\
由于其中存在如下决定关系：（课程名称）—>（学分），（学号）—>（姓名，年龄）\
即存在组合关键字中的字段决定非关键字的情况，所以不符合2NF\

会存在以下问题：\
1. 数据冗余：同一门课有n个学生选修，“学分”就重复n-1次；同一个学生修m门课程，姓名和年龄就重复了m-1次\
2. 更新异常：调整了某门课程的学分，需要将所以涉及该课程的行都进行更新，否则出现同一门课不同学分情况\
3. 插入异常：开设一门新的课程，暂时没人选修，由于没有“学号”关键字，课程名称和学分也无法插入数据库\
4. 删除异常：一批学生完成了课程的选修，要将选修记录从数据库表中删除，但是与此同时会删除掉课程名称和学分的信息\

可以将选课关系表改为如下三个表：Student（学号，姓名，年龄），Course（课程名称，学分），SelectCourse（学号，课程名称，成绩），这是符合2NF的\
注：所有单关键字的数据库表都符合2NF，因为不存在组合关键字

**第三范式（3NF）**：属性不依赖于其他非主属性（消除传递依赖）。要求一个数据库表中不包含已在其他表中包含的非主关键字信息

e.g. 学生表Student（学号，姓名，年龄，所在学院，学院地点，学院电话），单一关键字“学号”\
因为存在决定关系：（学号）—>（姓名，年龄，所在学院，学院地点，学院电话），这个数据库是符合2NF的\
但是由于存在决定关系：（学号）—>（所在学院）—>（学院地点，学院电话），这个数据库不符合3NF\
因为非关键字段“学院地点”、“学院电话”对非关键字“所在学院”存在依赖关系。这也会造成数据冗余、更新异常等\
可以将Student分成两个表：Student（学号，姓名，年龄，所在学院），Department（学院名称，学院地点，学院电话）

### 5.5 批处理&流处理

1. **批处理**
    
    Batch Processing，又称离线计算，其中大量的数据被收集、存储、然后批量地进行处理。数据在进入系统后，会被积累一段时间，然后在预定的时间点进行批量处理。
    
    特点：
    
    - 延迟：批处理通常有较高的延迟，因为数据需要等到一批数据收集完毕后才能处理。
    - 数据量：一次处理的数据量通常较大。
    - 使用场景：适用于不需要实时处理的数据分析、报告生成、数据迁移等任务。
2. **流处理**
    
    Stream Processing，又称实时计算，是一种实时数据处理模式，其中数据在生成后立即被处理。流处理系统能够持续接收和处理数据流，并实时输出结果。
    
    特点：
    
    - 低延迟：流处理具有较低的延迟，能够实时处理数据并生成结果。
    - 数据流：数据以连续流的形式输入系统，系统实时处理和分析。
    - 使用场景：适用于需要实时分析和响应的应用，如实时监控、实时推荐、金融交易监控等。

### 5.6 Lambda架构&Kappa架构

1. **lambda架构**
    
    ![Lambda架构示意图](../.vuepress/public/img/14.dw_develop_data_model_build/lambda_sample.png)
    
    Lambda架构是将批处理和流处理相结合的数据处理架构，旨在同时满足实时数据处理和历史数据处理的需求。Lambda架构通常包含三个层次：批处理层、速度层（实时处理层）和服务层。
    
    特点：
    
    - 批处理和实时处理结合：批处理层用于处理大量历史数据，生成批处理视图；速度层用于实时处理新到达的数据，生成实时视图。
    - 容错性：通过批处理和流处理的结合，系统能够确保数据的完整性和一致性。
    - 使用场景：适用于需要同时处理实时数据和批量数据的复杂系统，如金融风控系统、推荐系统等。
    
    e.g. 一家电子商务公司使用批流一体化架构来处理客户订单和推荐系统。批处理层每天处理历史订单数据，计算客户的购买偏好和趋势。速度层则实时处理新的订单和用户行为数据，快速更新推荐模型，为用户提供个性化的实时推荐。最终，服务层将批处理和实时处理的结果合并，提供统一的数据查询接口。
    
    lambda架构缺陷：
    
    - 双重逻辑维护复杂性：需要编写、维护、同步批处理、流处理两套代码
    - 一致性问题：批处理和流处理在不同时间段处理数据，有可能出现数据分析结果不一致
    - 资源利用率低
    - 数据模型接口复杂
2. **Kappa架构**
    
    ![Kappa架构示意图](../.vuepress/public/img/14.dw_develop_data_model_build/kappa_sample.png)
    
    Kappa架构是一种数据处理架构，旨在提供可扩展、容错且灵活的系统，用于实时处理大量数据。它是作为Lambda架构的替代方案开发的。它通过消除批处理层简化了大数据系统的设计，从而为处理实时数据提供了更简化的方法。
    特点：
    
    - 单一数据处理路径：Kappa架构强调使用流处理框架来处理历史数据和实时数据。数据流会被持久化到存储系统中，新的数据和历史数据都通过同一个数据处理路径流入系统。
    - 简化架构：通过移除批处理层，Kappa架构简化了系统的复杂性，避免了在Lambda架构中需要同时维护批处理和实时处理两套逻辑的情况。
    - 重放机制：在Kappa架构中，如果需要重新处理数据（例如，当有新的数据处理逻辑或修正错误时），可以通过重放历史数据流来实现。重放历史数据流类似于重新运行整个数据流的处理过程。
    
    Kappa架构适用于需要实时处理大量数据的各种用例，一些常见的用例包括：实时监控和警报、点击流分析、供应链优化
    

### 5.7 Kafka

Kafka在数据仓库中的角色主要是作为**实时数据流的传输和处理平台**。它帮助企业从各种数据源（如应用日志、数据库更新、传感器数据等）中持续采集数据，并将这些数据实时传输到数据仓库或其他数据存储和分析系统。

- **数据流的“快递员”**：
    
    Kafka就像一个高速快递员，负责从各个地方（比如应用程序、数据库等）收集数据，并快速、安全地把数据送到数据仓库里。
    
- **支持实时数据更新**：
    
    Kafka支持实时和历史数据统一处理，减少系统复杂性，适配Kappa架构的目标
    
- **高效处理大数据量**：
    
    Kafka擅长处理海量数据，它能够以高吞吐量处理每秒数百万条数据，让数据仓库可以接收和处理大规模的数据流，而不影响系统性能。
    
- **数据中转站**：
    
    Kafka不仅是数据的“快递员”，也是一个“中转站”，它可以把数据暂时存储在其中，然后根据需要把数据分发到多个地方，比如数据仓库、实时分析平台等。
    

## ***参考资料***

1. *企业文档《数据端【开发】必备进阶 流程规范之：工具掌握与规范流程》*
2. *企业文档《数据端【通用】必备进阶 知识技能之：数据建模和维度建模》*
3. *企业文档《数据端【开发】必备高阶-知识技能之：数据治理》*
4. *企业文档《数据端【开发】必备进阶-工具平台之：数据湖和iceberg》*
5. *网站《详解数仓中的数据分层：ODS、DWD、DWM、DWS、ADS》 [https://juejin.cn/post/6969874734355841031##heading-9](https://juejin.cn/post/6969874734355841031##heading-9)*
6. *网站《数据库范式详解》h[ttps://blog.csdn.net/ljp812184246/article/details/50706596](https://blog.csdn.net/ljp812184246/article/details/50706596)*
7. *网站《数据基础系列：Lambda架构和Kappa架构》[https://36kr.com/p/2817514161277190](https://36kr.com/p/2817514161277190)*
8. *书籍《大数据之路——阿里巴巴大数据实践》*
9. *B站视频《【一起啃书】阿里大数据之路数据仓库建模基础理论研读(已完结)》*
10. *ChatGPT、Google搜索*