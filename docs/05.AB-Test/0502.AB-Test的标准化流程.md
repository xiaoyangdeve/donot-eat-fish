---
title: AB-Test的标准化流程
date: 2023-03-14 11:28:40
permalink: /ab_test/8663f3/
categories:
  - A/B-Test
tags:
  - 
author: 
  name: 不爱吃鱼的bobo
---

## 一、确定一个好的目标和假设

### 1. A/B-Test能够解决什么业务问题

| 产品迭代                               | 算法优化                                           | 市场营销                 |
| -------------------------------------- | -------------------------------------------------- | ------------------------ |
| 如何改变用户的交互界面来提升用户的体验 | 如何通过提高算法推荐的准确度来提升用户的粘性       | 如何确定最优营销内容     |
| 如何优化新用户注册流程来提高转化率     | 如何通过提高搜索算法排名的准确度来提高用户的点击率 | 如何确定最优的营销时间   |
| 如何确定产品优惠券的最优价值           | 如何通过提高广告显示算法的精确度来提高广告的点击率 | 如何确定最精准的受众群体 |
| 如何增加产品功能来提升用户留存         | 如何通过距离算法的优化来计算乘客的最小路费         | 如何衡量市场营销的效果   |

- 所有的业务问题都有一个目标，比如提升用户粘性是业务问题的目标，同时我们也把这个目标称作**结果**。
- 有时候业务难题会有明确的努力方向，比如优化用户流程提升转化率，优化流程就是明确的努力方向。
- 有时有业务难题没有明确的努力方向，就需要我们仔细分析去发现原因，比如确定最优的有效内容。

### 2. 如何去确定目标和假设

1. 分析问题，确定想要达到的结果。
2. 提出业务问题的大体解决方案。
3. 从大体解决方案中提取出具体的假设。

一个好的假设应该是什么样子的

|        | 好的假设                                                     | 不好的假设                 |
| ------ | ------------------------------------------------------------ | -------------------------- |
| 来源   | 用户调研、数据挖掘、观察总结、数据分析等                     | 不基于事实和数据的主管猜测 |
| 因果   | 明确包含可能的原因和结果                                     | 可能的原因和结果不明确     |
| 可证伪 | 可被证伪                                                     | 模糊，很难证伪             |
| 可测量 | 定量的指标                                                   | 定性的结果                 |
| 例子   | 在某一个位置/操作结束后，增加某一个功能，可以带来某个指标的提升 | 我们的产品可以走向国际市场 |

- A/B 测试是因果推断，所以我们首先要确定原因和结果。
- 目标决定了结果（具体量化指标）， 而假设又决定了原因（具体动作），所以目标和假设对于 A/B 测试来说，是缺一不可。

## 二、如何选择一个合适的指标

### 1. 指标的分类

#### 1.1 评价指标（Evaluation Metrics）

​	一般是指能够驱动公司/组织**实现核心价值的指标**，又被称作驱动指标。

​	评价指标一般是**短期的，敏感的，有很强操作可行性**的。

​	例如：点击率、转化率、人均使用时长等

#### 1.2 护栏指标（Guardrail Metrics）

​	概括地说，护栏指标属于 A/B 测试中基本的合理性检验（Sanity Check），就像飞机起飞前的安全检查一样。它的作用就是作为辅助，来保障 A/B 测试的质量。

- 衡量A/B测试是否符合业务的长期目标，不会因为优化短期目标而打乱长期目标。
- 确保从统计上尽量减少出现各种偏差（Bias），得到尽可能值得信任的实验结果。

​	护栏指标作为辅助型指标，需要在评价指标选择好后进行确定。

### 2. 怎样选择评价指标

#### 2.1 评价指标的特征

- **可归因性**：我们选择的业务指标的变化（结果）必须要可以归因到实验中的变量（原因），需要做好控制标量。
- **可测量性**：能够很好的被量化和可测量，比如用户续订率就好于用户满意度。
- **敏感和稳定性**：如果实验中的变量变化了，评价指标要能敏感地做出相应的变化；但如果是其他因素变化了，评价指标要能保持相应的稳定性。业界通常采用 A/A 测试来测量稳定性，用回溯性分析来表征敏感性。
  - 和 A/B 测试类似，A/A 测试（A/A Test）也是把被测试对象分成实验组和对照组。但不同的是，A/A 测试中两组对象拥有的是完全相同的体验，如果 A/A 测试的结果发现两组的指标有显著不同，那么就说明要么分组分得不均匀，每组的数据分布差异较大；要么选取的指标波动范围太大，稳定性差。
  - 如果没有之前实验的数据，或者是因为某些原因（比如时间不够）没有办法跑新的实验，那我们也可以通过分析历史数据，进行**回溯性分析（Retrospective Analysis）**。也就是在分析之前不同的产品变化时，去看我们感兴趣的指标是否有相应的变化。

由此我可以获得下面两条经验：

1. **<font color='red'>用 A/B 测试来检测单次的变化时（比如单次推送 / 邮件）一般选用短期效果的指标，因为长期效果目标通常对单次变化并不敏感。</font>**

2. **<font color='red'>用 A/B 测试来检测连续的、永久的变化时（比如增加产品功能），可以选用长期效果的指标。</font>**

#### 2.2 选择合适的评价指标

1. **<font color='orange'>清楚业务和产品所处在的阶段，根据这个阶段的目标，来选择合适的评价指标。</font>**
2. **<font color='orange'>如果目标比较抽象，我们需要定性 + 定量来确定评价目标。</font>**
3. **<font color='orange'>如果有条件，通过公开或非公开的渠道，参考其他公司或组织的实验或者研究，根据自己的情况去借鉴他们的评价指标。</font>**

### 3. 综合多个指标，建立总体评价标准

​	结合多个指标，构建一个总体评价标准 （Overall Evaluation Criteria，简称 OEC）。

$$
OEC = \frac {(\Sigma_i Revevnue - S * Unsubscribe\_lifetime\_loss)} {n}
$$

- i，代表每一个用户。
- S，代表每组流失的用户数。
- Unsubscribe_lifetime_loss ，代表用户流失带来的预计的损失。
- n，代表每组的样本大小。

​	使用OEC的好处：

1. 综合各方面的指标，来把我整体的好坏，OEC中可能包含护栏指标。
2. OEC可以有效避免多重检验问题（Multiple Testing Problem）。
3. 不同指标的单位、大小可能不在一个尺度上，需要先要对各个指标进行归一化（Normalization）处理，使它们的取值都在一定的范围内，比如[0, 1]， 之后再进行结合，从而剔除指标单位 / 大小的影响。

### 4. 衡量评价指标的波动性

​	在统计学里面，指标的波动性通常用其平均值和平均值的标准差来表示，一个指标平均值的标准差越大，说明其波动性越大。这里面要注意，**变量平均值的标准差又叫做标准误差（Standard Error）**。

​	评价指标的正常波动范围，就是置信区间。

#### 4.1 根据统计公式来计算

​	**置信区间：**

$$
\text{置信区间}\:=\:\text{样本均值（}Sample\:Mean\text{）}\:±\:Z\text{分数}\:*\:\text{标准误差}
$$

​	**标准误差：**


$$
Stand\:Error=\left\{
\begin{aligned}
\sqrt{\frac {p(1\:-\:p)}{n}}\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\text{（概率类指标）}\\\\
\sqrt{\frac {s^2}{n}}\:=\:\sqrt{\frac{\Sigma^n_i{(x_i\:-\:\overline{x})^2}}{n(n\:-\:1)}} \:\:\:\:\:\:\:\:\:\:\:\:\:\text{（均值类指标）}
\end{aligned}
\right.
$$

​	其中，

- p 代表事件发生的概率
- s 代表样本的标准差
- n= 样本大小
- x<sub>i</sub>= 第 i 个用户的使用时长或者购买金额等
- $\overline{x}$= 用户的平均使用时长或者购买金额等。

#### 4.2 根据时间经验来确定

##### 4.2.1 A/A测试

​	我们可以跑多个不同样本大小的 A/A 测试，然后分别计算每个样本的指标大小，计算出来后，再把这些指标从小到大排列起来，并且去除最小 2.5% 和最大 2.5% 的值，剩下的就是 95% 的置信区间。

##### 4.2.2 Bootstraping算法

​	我们可以先跑一个样本很大的 A/A 测试，然后在这个大样本中进行随机可置换抽样（Random Sample with Replacement）， 抽取不同大小的样本来分别计算指标。然后采用和 A/A 测试一样的流程：把这些指标从小到大排列起来，并且去除最小 2.5% 和最大 2.5% 的值，得到 95% 的置信区间。

​	在实际应用中，Bootstrapping 会更流行些，因为只需要跑一次 A/A 测试，既节省时间也节省资源。

### 5. 护栏指标的选择

​	A/B 测试往往改变的是业务中的某一部分指标（评价指标），所以我们很容易只关注短期的改变，却失去了对业务的大局观（比如长期的盈利能力 / 用户体验）的掌控或者统计上合理性的检查。因此推荐每个 A/B 测试都要有相应的护栏指标。

​	护栏指标的选择可以从**业务品质和统计品质**两个方向进行选择。

<font color='#bf0031'>

| 业务品质 | 统计品质                      |
| -------- | ----------------------------- |
| 网络延迟 | 实验组/对照组样本量大小的比例 |
| 闪退率   | 实验组/对照组中特征的分布     |
| 人均指标 |                               |

</font>

#### 5.1 业务品质

##### 5.1.1 网络延迟

​	**网页加载时间、App 响应时间等，都是表征网络延迟的护栏指标**。增加产品功能可能会增加网页或 App 的响应时间，而且用户可以敏感地察觉出来。这个时候，就需要在 A/B 测试中加入表征网络延迟的护栏指标，确保在增加产品功能的同时，尽可能减少对用户体验的影响 （一般是通过优化底层代码）。

##### 5.1.2 闪退率

​	程序崩溃和闪退是非常影响用户的效率，很容易失去用户。所以，在测试应用程序的新功能和大改动时，尤其是针对一些大的改动，闪退率就是一个比较好的护栏指标。

##### 5.1.3 人均指标

​	人均指标可以从两个角度来考虑：

- 收入角度，比如人均花费、人均利润等。代表了产品的盈利能力。
- 用户参与度，比如人均使用时长、人均使用频率等。某种程度上代表用户的满意程度。

#### 5.2 统计品质

​	统计方面主要是尽可能多地消除偏差，使实验组和对照组尽可能相似，比如**检测两组样本量的比例，以及检测两组中特征的分布是否相似**。造成偏差的原因有很多，可能是随机分组的算法出现了 Bug，也可能是样本不够大，还有可能是触发实验条件的数据出现了延迟，不过更多的是具体实施中的工程问题造成的。

​	这些偏差都会影响我们获得准确的实验结果，而护栏指标就是我们发现这些偏差的利器。

##### 5.2.1 实验组/对照组样本量大小的比例

​	在设计 A/B 测试的时候，我们就会预先分配好实验组和对照组，通常是把样本等分。也就是说，实验组和对照组样本大小的比例，预期是 1:1=1。但有的时候，当实验结束后却发现两者的比例并不等于 1，甚至也没有很接近 1。这就说明这个实验在具体实施的过程中出现了问题，导致实验组和对照组出现了偏差。

##### 5.2.2 实验组/对照组中特征的分布

​	A/B 测试中一般采取随机分组，来保证两组实验对象是相似的，从而达到控制其他变量、只变化我们关心的唯一变量（即 A/B 测试中的原因）的目的。

​	比如说，如果以用户作为实验单位的话，那么，在试验结束后去分析两组数据时，两组中用户的年龄、性别、地点等基本信息的分布应该是大体一致的，这样才能消除偏差。否则，实验本身就是有问题的，得出的结果也不是可信赖的。

## 三、选取合适的实验单位

​	实验单位包括<font color='orange'>**用户层面、访问层面、页面层面**</font>三个方向，在每个方向上都有着不同的实验单位，**实验单位的准确度越高，A/B 测试结果的准确度才会越高。**	

| 用户层面                                                     | 访问层面                                                     | 页面层面                                                   |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------------------- |
| 用户ID，用户登陆、注册的ID，手机号、邮箱、user_id            | 把用户的每次访问作为一个最小单位，给定一个访问ID或会话ID     | 页面层面指的是把每一个新的页面浏览（Pageview）作为最小单位 |
| 匿名ID，用户浏览时的cookie                                   | 考虑到用户访问的复杂性，通常情况下，如果用户在某个网站、App 连续 30 分钟之内没有任何动作，系统就认定这次访问已经结束了。 |                                                            |
| 设备ID，设备出厂时绑定，区分设备，无法区分多个用户共享一个设备 |                                                              |                                                            |
| IP地址                                                       |                                                              |                                                            |
| 准确度由高到低：用户 ID > 匿名 ID（Cookies）/ 设备 ID > IP 地址。 | 一个用户经常访问，如果以访问层作为实验单位，可能出现一个用户同时出现在实验组和对照组 |                                                            |

​	通过上面各层实验单位的区分，我可以做如下对比：

1. **访问层面和页面层面的单位，比较适合变化不易被用户察觉的 A/B 测试，比如测试算法的改进、不同广告的效果等等；如果变化是容易被用户察觉的，那么建议你选择用户层面的单位。**
2. **从用户层面到访问层面再到页面层面，实验单位颗粒度越来越细，相应地可以从中获得更多的样本量。原因也很简单，一个用户可以有多个访问，而一个访问又可以包含多个页面浏览。**

### 1. 选取实验单位的原则

1. **保证用户体验的连贯性。**
2. **实验单位应与评价指标的单位保持一致。**
3. **样本数量要尽可能多。**

#### 1.1 保证用户体验的连贯性

​	如果A/B测试中对照组和实验组的变化，用户是能够感知到的，那么这个时候就需要选择用户层面的实验单位，避免用户产生困扰，这个功能时而能用时而不能用的感觉。

#### 1.2 实验单位与评价指标的单位保持一致

​	A/B 测试的一个前提是**实验单位相互独立且分布相同的（Independent and identically distributed），简称 IID**。如果两个单位不一致，就会违反相互独立这一前提，破坏了 A/B 测试的理论基础，从而导致实验结果不准确。

#### 1.3 样本数量要尽可能多

​	在 A/B 测试中，样本数量越多，实验结果就越准确。但增加样本量的方法有很多，我们绝对不能因为要获得更多的样本量，就选择颗粒度更细的实验单位，而不考虑前面两个原则。

​	所以我们选取实验单位的第三个原则就是：在保证用户体验连贯性、实验单位和评价指标的单位一致的前提下，可以尽可能地选择颗粒度更细的实验单位来增加样本量。

### 2. 实验单位选择决策图



<center><img src="/donot-eat-fish/img/ab_test/实验单位选取决策图.png" /></center>

## 四、选取实验样本量
​	在潜意识里，我们可能会认为样本量是越大越好，但是在现实中，样本量往往是越小越小。

​	因为，


$$
A/B \:\text{测试所需的时间}\:=\:\text{总样本量}\:/\:\text{每天可以得到的样本量}
$$
总样本量，在满足统计显著性检验的基础上越小越好，可以节省试错的时间，这个是符合互联网快速迭代的特点。

### 1. 样本量的计算逻辑

$$
n \:=\: \frac {(Z_{1-\frac{\alpha}{2}}\:+\: Z_{1-\beta})^2}{(\frac {\delta}{\sigma_{pooled}})^2}
\:=\:\frac {(Z_{1-\frac{\alpha}{2}}\:+\: Z_{power})^2}{(\frac {\delta}{\sigma_{pooled}})^2}
$$



​	其中： $Z_{1-\frac{\alpha}{2}}$ 为$(1 - \frac{\alpha}{2})$对应的$Z_score$。$Z_{power}$为Power对应的$Z_{score}$。

​	$\delta$为实验组和对照组评价指标的差值。

​	$\sigma_{pooled}^2$为实验组和对照组的综合方差（Polled Variance）。

​	从公式中，我们可以看出来，样本量主要由α、Power、δ和 $\delta_{pooled}^2$决定。我们要调整样本量的大小就靠这 4 个因素了，下面我们就来具体聊聊每个因素怎样影响样本量 n 的。

#### 1.1 统计功效Power（Statistical Power）是什么

​	Power，又被称作 Statistical Power。在统计理论中，第二类错误率β（Type II Error，Power = 1–β。

​	Power 的本质是概率，**在 A/B 测试中，如果实验组和对照组的指标事实上是不同的，Power 指的就是通过 A/B 测试探测到两者不同的概率。** Power 越大，说明 A/B 测试越能够准确地检测出实验组与对照组的不同（如果两组事实上是不同的 ）。**可以把Power理解为A/B测试的灵敏度**。

#### 1.2 四个因素和样本量 n 的关系

##### 1.2.1 显著性水平（Significance Level）α

​	显著水平和样本量成反比：**显著水平越小，样本量就越大**。这个也不难理解。因为显著水平又被称为第一类错误率（Type I Error）α，想要第一类错误率越小，结果越精确，就需要更大的样本量。

##### 1.2.2 统计功效Power(1 - β)

​	Power 和样本量成正比：**Power 越大，样本量就越大**。Power 越大，就说明第二类错误率（Type II Error）β越小。和第一类错误类似，想要第二类错误率越小，结果越精确，就需要更大的样本量。

##### 1.2.3 实验组和对照组的综合方差$\delta_{pooled}^2$

​	方差和样本量成正比：**方差越大，样本量就越大**。

​	方差是用来表征评价指标的波动性的，方差越大，说明评价指标的波动范围越大，也越不稳定，那就更需要更多的样本来进行实验，从而得到准确的结果。

##### 1.2.4 实验组和对照组评价指标的差值δ

​	差值和样本量成反比：**差值越小，样本量就越大**。因为实验组和对照组评价指标的差值越小，越不容易被 A/B 测试检测到，所以我们需要提高 Power，也就是说需要更多的样本量来保证准确度。

##### 1.2.5 四个因素总结

| 因素                                        | 因素变化 | 样本量大小变化 |
| ------------------------------------------- | :------: | :------------: |
| 显著性水平（Significance Level）α           | &#11014; |    &#11015;    |
| 统计功效Power(1 - β)                        | &#11014; |    &#11014;    |
| 实验组和对照组的综合方差$\delta_{pooled}^2$ | &#11014; |    &#11014;    |
| 实验组和对照组评价指标的差值δ               | &#11014; |    &#11015;    |

### 2. 怎样计算样本量

在实践中，绝大部分的 A/B 测试都会遵循统计中的惯例：把显著水平设置为默认的 5%，把 Power 设置为默认的 80%。这样的话我们就确定了公式中的 Z 分数，而且四个因素也确定了两个（α、Power）。那么，样本量大小就主要取决于剩下的两个因素：实验组和对照组的综合方差 $\delta_{pooled}^2$，以及两组评价指标的差值δ。因此实验组样本量计算的公式可以简化为：


$$
n\:\approx\:\frac{8\delta_{pooled}^2}{\delta^2}
$$


​	其中，方差是数据本身的属性（代表了数据的波动性），而两组间评价指标的差值则和 A/B 测试中的变量，以及变量对评价指标的影响有关。

​	以上公式其实是在两组评价指标的综合方差为 $\delta_{pooled}^2$，两组评价指标的差值为δ的情况下，要使 A/B 测试结果达到统计显著性的**最小样本量**。

​	注意，这里重点强调“最小”二字。理论上样本量越大越好，上不封顶，但实践中样本量越小越好，那我们就需要在这两者间找一个平衡。所以**由公式计算得到的样本量，其实是平衡二者后的最优样本量**。

#### 2.1 总体样本量

如果 A/B 测试的实验组和对照组样本量相等，即为 50%/50% 均分，那么我们的总样本量（实验组样本量和对照组样本量之和）为：


$$
n_{total}\:\approx\:2\:*\:\frac{8\delta_{pooled}^2}{\delta^2}\:\approx\: \frac{16\delta_{pooled}^2}{\delta^2}
$$
在实践中，我们最好把实验组和对照组的样本量配比设置为一样的。

一个常见的误解是，如果实验组的样本量大一些，对照组的样本量小一些（比如按照 80%/20% 分配），就能更快地获得统计上显著的结果。其实现实正好相反：两组不均分的话反而会延长测试的时间。

因为我们计算的达到统计显著性的最小样本量，是以每组为单位的，并不是以总体为单位。**也就是说，在非均分的情况下，只有相对较小组的样本量达到最小样本量，实验结果才有可能显著，并不是说实验组越大越好，因为瓶颈是在样本量较小的对照组上**。

相对于 50%/50% 的均分，非均分会出现两种结果，这两种结果均对业务不利。

- 准确度降低。如果保持相同的测试时间不变，那么对照组样本量就会变小，测试的 Power 也会变小，测试结果的准确度就会降低；
- 延长测试时间。如果保持对照组的样本量不变，那么就需要通过延长测试时间来收集更多的样本。所以只有两组均分，才能使两组的样本量均达到最大，并且使总样本量发挥最大使用效率，从而保证A/B 测试更快更准确地进行。

#### 2.2 估算实验组和对照组评价指标的差值δ

##### 2.2.1 从成本收益角度估算

在A/B测试中，我们期望能带来净收益。我们可以：

1. 先计算出整个迭代和实验需要的成本总和。
2. 在收支平衡时我们需要的评价指标差值。
3. 这个差值就是我们需要的$\delta$最小值。

##### 2.2.2 从历史数据中估算

如果从成本和收益中不好进行估算，我们可以从历史数据中进行估算。算出这些评价指标的平均值和波动范围，从而估算一个大概的差值。

比如说我们的评价指标是点击率，通过历史数据算出点击率的平均值为 5%，波动范围是[3.5%, 6.5%]，那么我们对实验组评价指标的期望值就是至少要大于这个波动范围，比如 7%，那么这时δ就等于 2%（7%–5%）。

#### 2.3 计算实验组和对照组的综合方差 $\delta_{pooled}^2$

$$
\delta_{pooled}^2=\left\{
\begin{aligned}
p_{test}(1-p_{test})\: + \:p_{control}(1\:+\:p_{control})\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\text{（概率类评价指标，二项分布）}\\\\
\frac{2\:*\:\Sigma_i^n(x_i - \overline{x})^2}{n - 1} \:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\text{（均值类评价指标，样本量大，中心极限定理）}
\end{aligned}
\right.
$$



其中：

- $p_{control}$为对照组中事件发生的概率，也就是没有 A/B 测试变化的情况，一般可以通过历史数据计算得出；$p_{test} = p_{control} + δ$，得出的是期望的实验组中事件发生的概率。
- n 为所取历史数据样本的大小。
- $x_i$为所取历史数据样本中第 i 个用户的使用时长 / 购买金额等。
- $\overline{x}$为所取历史数据样本中用户的平均使用时长 / 购买金额等。



## 五、分析测试结果

### 1. 什么时候可以分析测试结果


$$
A/B \:\text{测试所需的时间}\:=\:\text{总样本量}\:/\:\text{每天可以得到的样本量}
$$

其实，这个公式只是理论上推导，具体到 A/B 测试的实践中，我们要确定测试时间，除了考虑样本量的大小外，还要考虑指标周期性变化的因素。如果指标具有强烈的周期性变化，比如周中和周末的变化很大，那么这时候的**测试时间要包含至少一个周期的时间**，以排除指标周期性变化的影响。

- 在预计时间之前，评价指标出现了显著不同，这个时候是不可以提前结束实验的。提前结束可能导致下面两种情况：
  - **弃真错误**，因为样本量是不断变化的，所以每次观测到的测试其实都可以算作新的实验。随着实验时间和观测次数的增加，我们观察到第一类错误的概率会变大。
  - **假阳性错误**，提前观测到统计显著的结果，这就意味着样本量并没有达到事先估算的最小样本量，那么这个所谓的“统计显著的结果”就极有可能是错误的假阳性（False Positive）。“假阳性”是指，两组事实上是相同的，而测试结果错误地认为两组显著不同。

### 2. 合理性检验

#### 2.1 检验实验/对照组样本量的比例

我们预设的是，实验组和对照组的样本量各占总样本量的 50%，现在我们来看看实验过程中有没有发生什么变化。

各组样本量占总样本量的比例也是概率，也是**符合二项分布**的，所以具体的操作方法是：

1. 首先根据二项分布的公式$\sqrt{\frac{p(1-p)}{n}}$算出标准误差。
2. 然后，以 0.5（50%）为中心构建 95% 的置信区间。
3. 最后，确认实际的两组样本量的比例是否在置信区间内。如果总的比例在置信区间内的话，就说明即使总的比例不完全等于 50%/50%，也是非常接近，属于正常波动，两组样本量大小就符合预期。

#### 2.2 检验实验/对照组的特征分布

A/B 测试中实验组和对照组的数据要相似才具有可比性。这里的相似，我们可以通过比较两组的特征分布来判断。**常用的特征包括用户的年龄、性别、地点等基本信息，或者可能影响评价指标的特征**。

**<font color='red'>样本量分布和特征分布的合理性检验是都要进行的，这是保障实验质量的关键</font>**。这两种检验如果没有通过的话都会使实验结果不准确，可能会产生样本**比例不匹配问题和辛普森悖论**

- 样本比例不匹配（Sample Ratio Mismatch），实验 / 对照组样本量的比例和实验设计不相同。
- 辛普森悖论问题（Simpson Paradox），实验 / 对照组的特征分布不相似。

### 3. 分析A/B测试结果

分析 A/B 测试的结果，主要就是对比实验组和对照的评价指标是否有显著不同。其实，“显著”就是要排除偶然随机性的因素，通过统计的方法来证明两者的不同是事实存在的，而不是由于波动性造成的巧合。

首先我们可以用统计中的假设检验（Hypothesis Testing）计算出相关的统计量，然后再来分析测试的结果。**最常用的统计量是用 P 值（P value）和置信区间 (Confidence Interval)** 这两种统计量。

#### 3.1 正态总体成数（概率）类指标

##### 3.1.1 Z检验

当**评价指标为概率类指标**时（比如转化率，注册率等等），一般选用 Z 检验（在 A/B 测试中有时又被称为比例检验（Proportion Test））来计算出相应的 P 值和置信区间。

假设：

双侧检验


$$
\begin{aligned}
H_0:\:{P_1}\:=\:{P_2}\\
H_1:\:{P_1}\:\not=\:{P_2}\\
\end{aligned}
$$


左单侧检验


$$
\begin{aligned}
H_0:\:{P_1}\:=\:{P_2}\\
H_1:\:{P_1}\:<\:{P_2}\\
\end{aligned}
$$


右单侧检验


$$
\begin{aligned}
H_0:\:{P_1}\:=\:{P_2}\\
H_1:\:{P_1}\:>\:{P_2}\\
\end{aligned}
$$
当样本量$n_1,\: n_2$时（$n_1P_1,\: n_1P1(1-P_1),\:n_2P_2,\: n_2P2(1-P_2)$均大于5），两个样本的抽样分布渐近服从正态分布，即


$$
Z\:=\:\frac{({p_1} - {p_2}) -({P_1} - {P_2})}{\sqrt{\frac{P_1(1-P_1)}{n_1} - \frac{P2(1-P_2)}{n_1}}}
\sim N(0,\:1)
$$
由于$P_1,\:P_2$未知，我们要用$p_1,\:p_2$来进行估计，因此在原假设H0成立时，我们要以两个样本的合并概率作为两个总体概率的共同估计值，即


$$
\hat{P}\:=\:\frac{n_1p_1 + n_2p_2}{n_1+n_2}
$$
这样当原假设成立时，检验统计量为


$$
Z\:=\:\frac{p_1 - p_2}
{\sqrt{\hat{P}(\text{1} - \hat{P})(\frac{\text{1}}{n_1}+\frac{\text{1}}{n_2})}}
$$


#### 3.2 正态总体均值类指标

##### 3.2.1 Z检验

假设：

双侧检验

$\begin{aligned} H_0:\:\overline{X_1}\:=\:\overline{X_2}\\\ H_1:\:\overline{X_1}\:\not=\:\overline{X_2}\\\ \end{aligned}$
$$
\begin{aligned}
H_0:\:\overline{X_1}\:=\:\overline{X_2}\\
H_1:\:\overline{X_1}\:\not=\:\overline{X_2}\\
\end{aligned}
$$


左单侧检验


$$
\begin{aligned}
H_0:\:\overline{X_1}\:=\:\overline{X_2}\\
H_1:\:\overline{X_1}\:<\:\overline{X_2}\\
\end{aligned}
$$


右单侧检验


$$
\begin{aligned}
H_0:\:\overline{X_1}\:=\:\overline{X_2}\\
H_1:\:\overline{X_1}\:>\:\overline{X_2}\\
\end{aligned}
$$
由于总体样本的方差$S_1^2,\:S_2^2$很难计算，我们使用样本方差$s_1^2,\:s_2^2$进行估计。

那么当样本量$n_1,\: n_2$都足够大的情况下，统计量Z趋于服从标准正态分布


$$
Z\:=\:\frac{(\overline{x_1} - \overline{x_2}) -(\overline{X_1} - \overline{X_2})}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_1}}}
\sim N(0,\:1)
$$


当原假设成立，$\overline{X_1}\:=\:\overline{X_2}$成立时，我们可以构造检验统计量为：


$$
Z\:=\:\frac{\overline{x_1} - \overline{x_2}}
{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_1}}}
$$


##### 3.2.2 T检验

​	**两独立样本t检验**用于比较的**平均**两个独立的组是否存在差异。

###### **3.2.2.1 研究问题和统计假设**

典型的研究问题是：

1. A组均值（mA）是否*等于*B组均值（mB）？
2. A组均值（mA）是否*小于*B组均值（mB）？
3. A组均值（mA）是否*大于*B组均值（mB）？

在统计数据中，我们可以定义相应的无效*假设*（H0） 如下：

1. H0：mA = mB
2. H0：mA ≤ mB
3. H0：mA ≥ mB

相应的*备择假设*（H1）如下：

1. H1：mA ≠ mB （不同）
2. H1：mA > mB（大于）
3. H1：mA < mB（小于）

注意：

- 假设1）称为**双向检验**
- 假设2）和3）称为**单向检验**

###### 3.2.2.2 当两组总体方差相等（齐性）

$$
\text{t} = \frac{mA - mB}{\sqrt{\frac{S^2}{nA} + \frac{S^2}{nB}}}
$$





其中，

- **mA和mB分别**是A、B两组样本**均值**
- **nA和nB分别**是A、B两组样本**量**
- **s2**是样本**的标准差，可以由以下公式计算获得**

$$
S^2 = \frac{\Sigma{(x - mA)}^2 + \Sigma{(x - mB)}^2} {nA + nB - 2}
$$



我们可以**为自由度**（df）计算与**t检验统计量**（| t |），通过查询t分布表格对比其在df=nA+nB-2处的P值。

###### 3.2.2.2 当两组总体方差不相等

当两组方差不相等（方差不齐）时，可以使用校正的student-t检验方法，即Welch t检验比较两组差异：
$$
\text{t} = \frac{mA - mB}{\sqrt{\frac{S^2_A}{nA} + \frac{S_B^2}{nB}}}
$$
其中，

- SA和SB 分别是两组A和B的标准差。
- 与经典的student-t检验不同，**Welch t检验公式**涉及两组的方差（SA2和SB2）进行比较。而不能将其直接合并为S2。
- 其自由度的计算公式如下：

$$
\text{df}= \frac{ \frac{S_A^2}{nA} + \frac{S_B^2}{nB}}{ \frac{S_A^4}{nA^2(nB - 1)} + \frac{S_B^4}{nB^2(nA - 1)}}
$$



注意，Welch t检验被认为是一种相对保守安全的检验方法。

通常，除非组大小和标准差都非常不同，否则**经典的student-t检验**和**Welch t检验的**结果非常相似。



#### 3.3 Bootstrapping

当评价指标的分布比较复杂，在大样本量下也不能近似成正态分布时（比如 70% 用户的使用时间，OEC 等），一般采用 Bootstrapping 的方法，从 P 值或者置信区间的定义来计算 P 值和置信区间。

